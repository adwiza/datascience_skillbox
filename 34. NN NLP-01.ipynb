{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3180a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c01e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text   \n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  \\\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at   \n",
       "0                          iPhone  \\\n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/brand_tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3e86a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3904, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df[df.tweet_text.isnull()].index, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "079a83e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_str = df.tweet_text.values[0]\n",
    "sample_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe69ad50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Исходный текст == \n",
      ".@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.\n",
      "\n",
      "\n",
      "== Токенизированный текст == \n",
      "['.', '@', 'wesley83', 'I', 'have', 'a', '3G', 'iPhone', '.', 'After', '3', 'hrs', 'tweeting', 'at', '#', 'RISE_Austin', ',', 'it', 'was', 'dead', '!', 'I', 'need', 'to', 'upgrade', '.', 'Plugin', 'stations', 'at', '#', 'SXSW', '.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('== Исходный текст == \\n%s\\n\\n' % sample_str)\n",
    "\n",
    "tokenized_str = nltk.word_tokenize(sample_str)\n",
    "\n",
    "print('== Токенизированный текст == \\n%s\\n\\n' % tokenized_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0273101b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wesley83', 'i', 'have', 'a', '3g', 'iphone', 'after', '3', 'hrs', 'tweeting', 'at', 'rise_austin', 'it', 'was', 'dead', 'i', 'need', 'to', 'upgrade', 'plugin', 'stations', 'at', 'sxsw']\n"
     ]
    }
   ],
   "source": [
    "tokens = [i.lower() for i in tokenized_str if (i not in string.punctuation)]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e40e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "# stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "099053d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wesley83', '3g', 'iphone', '3', 'hrs', 'tweeting', 'rise_austin', 'dead', 'need', 'upgrade', 'plugin', 'stations', 'sxsw']\n"
     ]
    }
   ],
   "source": [
    "filtered_tokens = [i for i in tokens if (i not in stop_words)]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "016dd98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(raw_text: str):\n",
    "    \"\"\"\n",
    "    Функция для токенизации текста\n",
    "    :param raw_text: исходная текстовая строка\n",
    "    \"\"\"\n",
    "    tokenized_str = nltk.word_tokenize(raw_text)\n",
    "    tokens = [i.lower() for i in tokenized_str if (i not in string.punctuation)]\n",
    "    filtered_tokens = [i for i in tokens if (i not in stop_words)]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa2b594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweets = df.tweet_text.apply(tokenize_text)\n",
    "df = df.assign(tokenized=tokenized_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a0dde23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [wesley83, 3g, iphone, 3, hrs, tweeting, rise_...\n",
       "1    [jessedee, know, fludapp, awesome, ipad/iphone...\n",
       "2        [swonderlin, wait, ipad, 2, also, sale, sxsw]\n",
       "3    [sxsw, hope, year, 's, festival, n't, crashy, ...\n",
       "4    [sxtxstate, great, stuff, fri, sxsw, marissa, ...\n",
       "Name: tokenized, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90bfd084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=tokenize_text)\n",
    "document_matrix = vectorizer.fit_transform(df.tweet_text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec0604fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3904x7258 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 46023 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "918e3cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_char_ngrams',\n",
       " '_char_wb_ngrams',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_check_stop_words_consistency',\n",
       " '_check_vocabulary',\n",
       " '_count_vocab',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_limit_features',\n",
       " '_more_tags',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_sort_features',\n",
       " '_validate_data',\n",
       " '_validate_ngram_range',\n",
       " '_validate_params',\n",
       " '_validate_vocabulary',\n",
       " '_warn_for_unused_params',\n",
       " '_white_spaces',\n",
       " '_word_ngrams',\n",
       " 'build_analyzer',\n",
       " 'build_preprocessor',\n",
       " 'build_tokenizer',\n",
       " 'decode',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'get_feature_names_out',\n",
       " 'get_params',\n",
       " 'get_stop_words',\n",
       " 'inverse_transform',\n",
       " 'set_params',\n",
       " 'transform']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d16e3b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_tweet_index = 0\n",
    "\n",
    "df.tweet_text.values[source_tweet_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0055147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "tweet_distance = 1 - pairwise_distances(\n",
    "    document_matrix, \n",
    "    metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "896d6571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3904, 3904)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_distance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f073551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,  633,  420, ...,  579, 3771, 1330])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sorted_similarity = np.argsort(-tweet_distance[source_tweet_index, :])\n",
    "sorted_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7acd0221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.\n",
      "-------------\n",
      ".@mention I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.\n",
      "-------------\n",
      "IPhone is dead. Find me on the secret batphone #sxsw.\n",
      "-------------\n",
      "The big takeaway from #SXSW interactive - I need an iphone.\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[source_tweet_index].tweet_text)\n",
    "print('-------------')\n",
    "print(df.iloc[sorted_similarity[1]].tweet_text)\n",
    "print('-------------')\n",
    "print(df.iloc[sorted_similarity[2]].tweet_text)\n",
    "print('-------------')\n",
    "print(df.iloc[sorted_similarity[3]].tweet_text)\n",
    "print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a25da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s : %(levelname)s : %(message)s', \n",
    "    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eba42856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['wesley83', '3g', 'iphone', '3', 'hrs', 'tweeting', 'rise_austin', 'dead', 'need', 'upgrade', 'plugin', 'stations', 'sxsw']),\n",
       "       list(['jessedee', 'know', 'fludapp', 'awesome', 'ipad/iphone', 'app', \"'ll\", 'likely', 'appreciate', 'design', 'also', \"'re\", 'giving', 'free', 'ts', 'sxsw']),\n",
       "       list(['swonderlin', 'wait', 'ipad', '2', 'also', 'sale', 'sxsw'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = df.tokenized.values\n",
    "texts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75924a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 06:35:18,125 : INFO : collecting all words and their counts\n",
      "2023-06-16 06:35:18,126 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-06-16 06:35:18,137 : INFO : collected 7253 word types from a corpus of 48371 raw words and 3904 sentences\n",
      "2023-06-16 06:35:18,138 : INFO : Creating a fresh vocabulary\n",
      "2023-06-16 06:35:18,188 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 3083 unique words (42.51% of original 7253, drops 4170)', 'datetime': '2023-06-16T06:35:18.188931', 'gensim': '4.3.1', 'python': '3.8.12 | packaged by conda-forge | (default, Sep 29 2021, 19:21:23) \\n[Clang 11.1.0 ]', 'platform': 'macOS-13.4-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-06-16 06:35:18,189 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 44201 word corpus (91.38% of original 48371, drops 4170)', 'datetime': '2023-06-16T06:35:18.189387', 'gensim': '4.3.1', 'python': '3.8.12 | packaged by conda-forge | (default, Sep 29 2021, 19:21:23) \\n[Clang 11.1.0 ]', 'platform': 'macOS-13.4-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-06-16 06:35:18,225 : INFO : deleting the raw counts dictionary of 7253 items\n",
      "2023-06-16 06:35:18,226 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-06-16 06:35:18,226 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 30559.5292511215 word corpus (69.1%% of prior 44201)', 'datetime': '2023-06-16T06:35:18.226385', 'gensim': '4.3.1', 'python': '3.8.12 | packaged by conda-forge | (default, Sep 29 2021, 19:21:23) \\n[Clang 11.1.0 ]', 'platform': 'macOS-13.4-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-06-16 06:35:18,255 : INFO : estimated required memory for 3083 words and 10 dimensions: 1788140 bytes\n",
      "2023-06-16 06:35:18,256 : INFO : resetting layer weights\n",
      "2023-06-16 06:35:18,257 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-06-16T06:35:18.257105', 'gensim': '4.3.1', 'python': '3.8.12 | packaged by conda-forge | (default, Sep 29 2021, 19:21:23) \\n[Clang 11.1.0 ]', 'platform': 'macOS-13.4-arm64-arm-64bit', 'event': 'build_vocab'}\n",
      "2023-06-16 06:35:18,257 : INFO : Word2Vec lifecycle event {'msg': 'training model with 7 workers on 3083 vocabulary and 10 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-06-16T06:35:18.257459', 'gensim': '4.3.1', 'python': '3.8.12 | packaged by conda-forge | (default, Sep 29 2021, 19:21:23) \\n[Clang 11.1.0 ]', 'platform': 'macOS-13.4-arm64-arm-64bit', 'event': 'train'}\n",
      "2023-06-16 06:35:18,269 : INFO : EPOCH 0: training on 48371 raw words (30524 effective words) took 0.0s, 3527579 effective words/s\n",
      "2023-06-16 06:35:18,280 : INFO : EPOCH 1: training on 48371 raw words (30623 effective words) took 0.0s, 3872122 effective words/s\n",
      "2023-06-16 06:35:18,291 : INFO : EPOCH 2: training on 48371 raw words (30570 effective words) took 0.0s, 3763040 effective words/s\n",
      "2023-06-16 06:35:18,302 : INFO : EPOCH 3: training on 48371 raw words (30590 effective words) took 0.0s, 4330075 effective words/s\n",
      "2023-06-16 06:35:18,313 : INFO : EPOCH 4: training on 48371 raw words (30541 effective words) took 0.0s, 3737121 effective words/s\n",
      "2023-06-16 06:35:18,324 : INFO : EPOCH 5: training on 48371 raw words (30537 effective words) took 0.0s, 3864994 effective words/s\n",
      "2023-06-16 06:35:18,335 : INFO : EPOCH 6: training on 48371 raw words (30401 effective words) took 0.0s, 3737522 effective words/s\n",
      "2023-06-16 06:35:18,346 : INFO : EPOCH 7: training on 48371 raw words (30633 effective words) took 0.0s, 3749908 effective words/s\n",
      "2023-06-16 06:35:18,357 : INFO : EPOCH 8: training on 48371 raw words (30599 effective words) took 0.0s, 3806931 effective words/s\n",
      "2023-06-16 06:35:18,368 : INFO : EPOCH 9: training on 48371 raw words (30442 effective words) took 0.0s, 3655197 effective words/s\n",
      "2023-06-16 06:35:18,368 : INFO : Word2Vec lifecycle event {'msg': 'training on 483710 raw words (305460 effective words) took 0.1s, 2756664 effective words/s', 'datetime': '2023-06-16T06:35:18.368626', 'gensim': '4.3.1', 'python': '3.8.12 | packaged by conda-forge | (default, Sep 29 2021, 19:21:23) \\n[Clang 11.1.0 ]', 'platform': 'macOS-13.4-arm64-arm-64bit', 'event': 'train'}\n",
      "2023-06-16 06:35:18,369 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=3083, vector_size=10, alpha=0.025>', 'datetime': '2023-06-16T06:35:18.369012', 'gensim': '4.3.1', 'python': '3.8.12 | packaged by conda-forge | (default, Sep 29 2021, 19:21:23) \\n[Clang 11.1.0 ]', 'platform': 'macOS-13.4-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# CBOW\n",
    "model = Word2Vec(\n",
    "    texts, \n",
    "    vector_size=10, \n",
    "    window=7, \n",
    "    min_count=2,\n",
    "    workers=7, \n",
    "    epochs=10, \n",
    "    sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d4ccbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x282d26490>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3862798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.059951  ,  0.08012879,  1.7577075 , -0.86151916,  1.249628  ,\n",
       "       -0.03899164,  2.2073784 ,  1.974332  , -1.2460318 , -2.0890038 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('android')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1ae9275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blackberry', 0.9929759502410889),\n",
       " ('iphone', 0.9861955046653748),\n",
       " ('witnessed', 0.9823786616325378),\n",
       " ('cheers', 0.9805057048797607),\n",
       " ('q', 0.9786323308944702),\n",
       " ('amp', 0.9769442677497864),\n",
       " ('hootsuite', 0.9755609631538391),\n",
       " ('ranking', 0.9753310084342957),\n",
       " ('shared', 0.9746308326721191),\n",
       " ('pocket', 0.9744592905044556)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('android')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "070d9194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 06:36:22,195 : INFO : collecting all words and their counts\n",
      "2023-06-16 06:36:22,196 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-06-16 06:36:22,208 : INFO : collected 7253 word types from a corpus of 48371 raw words and 3904 sentences\n",
      "2023-06-16 06:36:22,208 : INFO : Creating a fresh vocabulary\n",
      "2023-06-16 06:36:22,259 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 3083 unique words (42.51% of original 7253, drops 4170)', 'datetime': '2023-06-16T06:36:22.259209', 'gensim': '4.3.1', 'python': '3.8.12 | packaged by conda-forge | (default, Sep 29 2021, 19:21:23) \\n[Clang 11.1.0 ]', 'platform': 'macOS-13.4-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-06-16 06:36:22,259 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 44201 word corpus (91.38% of original 48371, drops 4170)', 'datetime': '2023-06-16T06:36:22.259725', 'gensim': '4.3.1', 'python': '3.8.12 | packaged by conda-forge | (default, Sep 29 2021, 19:21:23) \\n[Clang 11.1.0 ]', 'platform': 'macOS-13.4-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-06-16 06:36:22,296 : INFO : deleting the raw counts dictionary of 7253 items\n",
      "2023-06-16 06:36:22,297 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2023-06-16 06:36:22,297 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 30559.5292511215 word corpus (69.1%% of prior 44201)', 'datetime': '2023-06-16T06:36:22.297848', 'gensim': '4.3.1', 'python': '3.8.12 | packaged by conda-forge | (default, Sep 29 2021, 19:21:23) \\n[Clang 11.1.0 ]', 'platform': 'macOS-13.4-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-06-16 06:36:22,327 : INFO : estimated required memory for 3083 words and 10 dimensions: 1788140 bytes\n",
      "2023-06-16 06:36:22,327 : INFO : resetting layer weights\n",
      "2023-06-16 06:36:22,328 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-06-16T06:36:22.328686', 'gensim': '4.3.1', 'python': '3.8.12 | packaged by conda-forge | (default, Sep 29 2021, 19:21:23) \\n[Clang 11.1.0 ]', 'platform': 'macOS-13.4-arm64-arm-64bit', 'event': 'build_vocab'}\n",
      "2023-06-16 06:36:22,329 : INFO : Word2Vec lifecycle event {'msg': 'training model with 7 workers on 3083 vocabulary and 10 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-06-16T06:36:22.329047', 'gensim': '4.3.1', 'python': '3.8.12 | packaged by conda-forge | (default, Sep 29 2021, 19:21:23) \\n[Clang 11.1.0 ]', 'platform': 'macOS-13.4-arm64-arm-64bit', 'event': 'train'}\n",
      "2023-06-16 06:36:22,348 : INFO : EPOCH 0: training on 48371 raw words (30548 effective words) took 0.0s, 1969695 effective words/s\n",
      "2023-06-16 06:36:22,366 : INFO : EPOCH 1: training on 48371 raw words (30465 effective words) took 0.0s, 2034023 effective words/s\n",
      "2023-06-16 06:36:22,384 : INFO : EPOCH 2: training on 48371 raw words (30516 effective words) took 0.0s, 2025533 effective words/s\n",
      "2023-06-16 06:36:22,403 : INFO : EPOCH 3: training on 48371 raw words (30582 effective words) took 0.0s, 1908329 effective words/s\n",
      "2023-06-16 06:36:22,421 : INFO : EPOCH 4: training on 48371 raw words (30564 effective words) took 0.0s, 1950655 effective words/s\n",
      "2023-06-16 06:36:22,439 : INFO : EPOCH 5: training on 48371 raw words (30564 effective words) took 0.0s, 2000742 effective words/s\n",
      "2023-06-16 06:36:22,457 : INFO : EPOCH 6: training on 48371 raw words (30551 effective words) took 0.0s, 1980049 effective words/s\n",
      "2023-06-16 06:36:22,474 : INFO : EPOCH 7: training on 48371 raw words (30670 effective words) took 0.0s, 2143494 effective words/s\n",
      "2023-06-16 06:36:22,492 : INFO : EPOCH 8: training on 48371 raw words (30517 effective words) took 0.0s, 2017142 effective words/s\n",
      "2023-06-16 06:36:22,510 : INFO : EPOCH 9: training on 48371 raw words (30595 effective words) took 0.0s, 2140228 effective words/s\n",
      "2023-06-16 06:36:22,510 : INFO : Word2Vec lifecycle event {'msg': 'training on 483710 raw words (305572 effective words) took 0.2s, 1686938 effective words/s', 'datetime': '2023-06-16T06:36:22.510567', 'gensim': '4.3.1', 'python': '3.8.12 | packaged by conda-forge | (default, Sep 29 2021, 19:21:23) \\n[Clang 11.1.0 ]', 'platform': 'macOS-13.4-arm64-arm-64bit', 'event': 'train'}\n",
      "2023-06-16 06:36:22,510 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=3083, vector_size=10, alpha=0.025>', 'datetime': '2023-06-16T06:36:22.510954', 'gensim': '4.3.1', 'python': '3.8.12 | packaged by conda-forge | (default, Sep 29 2021, 19:21:23) \\n[Clang 11.1.0 ]', 'platform': 'macOS-13.4-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# SKIP GRAM\n",
    "model = Word2Vec(\n",
    "    texts, \n",
    "    vector_size=10, \n",
    "    window=7, \n",
    "    min_count=2,\n",
    "    workers=7, \n",
    "    epochs=10, \n",
    "    sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dfa7371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('app', 0.9378886818885803),\n",
       " ('show', 0.9139389395713806),\n",
       " ('grape', 0.9023708701133728),\n",
       " ('share', 0.894133985042572),\n",
       " ('see', 0.8904950618743896),\n",
       " ('guide', 0.8875192403793335),\n",
       " ('get', 0.8871597647666931),\n",
       " ('working', 0.8865310549736023),\n",
       " ('check', 0.8849830627441406),\n",
       " ('must', 0.8840959668159485)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('iphone')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipyflow)",
   "language": "python",
   "name": "ipyflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
