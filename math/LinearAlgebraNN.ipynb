{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6fecc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 06:35:53.431996: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ef55619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.774964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 06:36:01.839762: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-24 06:36:01.841371: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "vector = tf.constant([[4,5,6]], dtype=tf.float32)\n",
    "eucNorm = tf.norm(vector, ord=\"euclidean\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(eucNorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3a1050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "matrix1 = [[1.0, 2.0], [3.0, 40]]\n",
    "matrix2 = np.array([[1.0, 2.0], [3.0, 40]], dtype=np.float32)\n",
    "matrix3 = tf.constant([[1.0, 2.0], [3.0, 40]])\n",
    "\n",
    "print(type(matrix1))\n",
    "print(type(matrix2))\n",
    "print(type(matrix3))\n",
    "\n",
    "tensorForM1 = tf.convert_to_tensor(matrix1, dtype=tf.float32)\n",
    "tensorForM2 = tf.convert_to_tensor(matrix2, dtype=tf.float32)\n",
    "tensorForM3 = tf.convert_to_tensor(matrix3, dtype=tf.float32)\n",
    "\n",
    "print(type(tensorForM1))\n",
    "print(type(tensorForM2))\n",
    "print(type(tensorForM3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d992c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28 40 54]\n",
      " [30 22 12]]\n",
      "[[122 167]\n",
      " [ 46  64]]\n"
     ]
    }
   ],
   "source": [
    "mat1 = tf.constant([[4, 5, 6],[3,2,1]])\n",
    "mat2 = tf.constant([[7, 8, 9],[10, 11, 12]])\n",
    "\n",
    "mult = tf.multiply(mat1, mat2)\n",
    "\n",
    "dotprod = tf.matmul(mat1, tf.transpose(mat2))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(mult))\n",
    "    print(sess.run(dotprod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e131ec63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n"
     ]
    }
   ],
   "source": [
    "mat = tf.constant([\n",
    " [0, 1, 2],\n",
    " [3, 4, 5],\n",
    " [6, 7, 8]\n",
    "], dtype=tf.float32)\n",
    "\n",
    "mat = tf.trace(mat)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce9232c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n",
      "[[[1 6]\n",
      "  [2 5]\n",
      "  [3 4]]\n",
      "\n",
      " [[4 3]\n",
      "  [5 6]\n",
      "  [6 3]]]\n"
     ]
    }
   ],
   "source": [
    "x = [[1,2,3],[4,5,6]]\n",
    "x = tf.convert_to_tensor(x)\n",
    "xtrans = tf.transpose(x)\n",
    "\n",
    "y=([[[1,2,3],[6,5,4]],[[4,5,6],[3,6,3]]])\n",
    "y = tf.convert_to_tensor(y)\n",
    "ytrans = tf.transpose(y, perm=[0, 2, 1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "   print(sess.run(xtrans))\n",
    "   print(sess.run(ytrans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab2ad1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 4. 8.]\n",
      "[[1 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 4]]\n"
     ]
    }
   ],
   "source": [
    "mat = tf.constant([\n",
    " [0, 1, 2],\n",
    " [3, 4, 5],\n",
    " [6, 7, 8]\n",
    "], dtype=tf.float32)\n",
    "\n",
    "diag_mat = tf.diag_part(mat)\n",
    "\n",
    "mat = tf.diag([1,2,3,4])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "   print(sess.run(diag_mat))\n",
    "   print(sess.run(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ab147a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "identity = tf.eye(3, 3)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "   print(sess.run(identity))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6f9f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x**2 + y**2 + -2.0x + -6.0y + 5.0 = 0\n"
     ]
    }
   ],
   "source": [
    "# x2+y2+dx+ey+f = 0\n",
    "# dx+ey+f=−(x2+y2) ==> AX = B\n",
    "# d, e, f\n",
    "\n",
    "points = tf.constant([[2,1], [0,5], [-1,2]], dtype=tf.float64)\n",
    "X = tf.constant([[2,1,1], [0,5,1], [-1,2,1]], dtype=tf.float64)\n",
    "B = -tf.constant([[5], [25], [5]], dtype=tf.float64)\n",
    "\n",
    "A = tf.matrix_solve(X,B)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(A)\n",
    "    D, E, F = result.flatten()\n",
    "    print(\"x**2 + y**2 + {D}x + {E}y + {F} = 0\".format(**locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e5b9d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.2412510e-01  5.7285953e-01  9.5445983e-02  3.8322863e-01\n",
      "   1.7696340e-01 -1.7609245e-01  4.1918576e-01  5.5770501e-02]\n",
      " [ 5.9443843e-01 -6.3012099e-01 -1.7020741e-01  3.1003842e-01\n",
      "  -1.8406223e-01 -2.3477782e-01 -1.2953560e-01 -1.3681325e-01]\n",
      " [ 2.5627419e-01 -2.7401772e-01  1.5981109e-01  6.5319000e-08\n",
      "   5.7898474e-01  6.3655090e-01  2.1452342e-07  3.0541500e-01]\n",
      " [ 2.8563744e-01  2.4791259e-01  3.5461003e-01 -7.3189922e-02\n",
      "  -4.4578463e-01  8.3614528e-02 -5.4872149e-01  4.6801224e-01]\n",
      " [ 1.9313939e-01 -3.3849932e-02 -5.0079018e-01 -4.2846254e-01\n",
      "  -3.4711048e-01  1.5548302e-01  4.6866363e-01  4.0357691e-01]\n",
      " [ 3.0513468e-01  2.9398909e-01 -2.2343382e-01 -1.9161446e-01\n",
      "  -1.2746094e-01  4.9121961e-01 -2.0959236e-01 -6.5753585e-01]\n",
      " [ 1.8248993e-01  1.6102767e-01 -3.9784253e-01 -3.8322884e-01\n",
      "   5.1292336e-01 -4.2757425e-01 -4.1918600e-01  1.1831376e-01]\n",
      " [ 2.4689846e-01 -1.5725437e-01  5.9299219e-01 -6.2007719e-01\n",
      "   3.2186557e-02 -2.3106529e-01  2.5907102e-01 -2.3797689e-01]]\n",
      "[2.7572641  2.6782503  1.8922135  1.6180354  1.1915464  0.9483402\n",
      " 0.6180348  0.56999254]\n",
      "[[ 5.2412516e-01 -5.7285923e-01 -9.5446005e-02  3.8322866e-01\n",
      "   1.7696351e-01  1.7609236e-01 -4.1918585e-01  5.5770084e-02]\n",
      " [ 5.9443843e-01  6.3012111e-01  1.7020735e-01  3.1003860e-01\n",
      "  -1.8406229e-01  2.3477778e-01  1.2953569e-01 -1.3681309e-01]\n",
      " [ 2.5627407e-01  2.7401769e-01 -1.5981109e-01 -6.7946758e-08\n",
      "   5.7898462e-01 -6.3655108e-01 -4.6661830e-07  3.0541503e-01]\n",
      " [ 2.8563747e-01 -2.4791244e-01 -3.5461015e-01 -7.3189929e-02\n",
      "  -4.4578466e-01 -8.3614394e-02  5.4872108e-01  4.6801290e-01]\n",
      " [ 1.9313939e-01  3.3849966e-02  5.0079036e-01 -4.2846251e-01\n",
      "  -3.4711057e-01 -1.5548284e-01 -4.6866414e-01  4.0357652e-01]\n",
      " [ 3.0513480e-01 -2.9398894e-01  2.2343381e-01 -1.9161427e-01\n",
      "  -1.2746108e-01 -4.9121952e-01  2.0959297e-01 -6.5753555e-01]\n",
      " [ 1.8248996e-01 -1.6102758e-01  3.9784259e-01 -3.8322887e-01\n",
      "   5.1292342e-01  4.2757443e-01  4.1918600e-01  1.1831414e-01]\n",
      " [ 2.4689844e-01  1.5725447e-01 -5.9299213e-01 -6.2007719e-01\n",
      "   3.2186668e-02  2.3106527e-01 -2.5907087e-01 -2.3797715e-01]]\n",
      "[[-5.2412492e-01 -5.7285917e-01  9.5446303e-02  3.8322848e-01\n",
      "   1.7696337e-01 -1.7609218e-01  4.1918561e-01 -5.5770274e-02]\n",
      " [-5.9443808e-01  6.3012064e-01 -1.7020778e-01  3.1003836e-01\n",
      "  -1.8406233e-01 -2.3477785e-01 -1.2953548e-01  1.3681313e-01]\n",
      " [-2.5627401e-01  2.7401754e-01  1.5981084e-01 -1.6653345e-16\n",
      "   5.7898462e-01  6.3655090e-01  4.1633363e-16 -3.0541489e-01]\n",
      " [-2.8563741e-01 -2.4791212e-01  3.5461032e-01 -7.3190130e-02\n",
      "  -4.4578448e-01  8.3614141e-02 -5.4872108e-01 -4.6801242e-01]\n",
      " [-1.9313931e-01  3.3849504e-02 -5.0079042e-01 -4.2846248e-01\n",
      "  -3.4711021e-01  1.5548323e-01  4.6866375e-01 -4.0357655e-01]\n",
      " [-3.0513468e-01 -2.9398900e-01 -2.2343360e-01 -1.9161424e-01\n",
      "  -1.2746094e-01  4.9121940e-01 -2.0959280e-01  6.5753537e-01]\n",
      " [-1.8248984e-01 -1.6102777e-01 -3.9784244e-01 -3.8322848e-01\n",
      "   5.1292324e-01 -4.2757443e-01 -4.1918561e-01 -1.1831383e-01]\n",
      " [-2.4689843e-01  1.5725476e-01  5.9299165e-01 -6.2007672e-01\n",
      "   3.2186814e-02 -2.3106508e-01  2.5907096e-01  2.3797691e-01]]\n",
      "[2.7572627 2.678248  1.8922127 1.618034  1.1915456 0.9483398 0.618034\n",
      " 0.5699922]\n",
      "[[-5.2412492e-01 -5.9443808e-01 -2.5627401e-01 -2.8563741e-01\n",
      "  -1.9313931e-01 -3.0513468e-01 -1.8248984e-01 -2.4689843e-01]\n",
      " [ 5.7285917e-01 -6.3012064e-01 -2.7401754e-01  2.4791212e-01\n",
      "  -3.3849504e-02  2.9398900e-01  1.6102777e-01 -1.5725476e-01]\n",
      " [-9.5446303e-02  1.7020778e-01 -1.5981084e-01 -3.5461032e-01\n",
      "   5.0079042e-01  2.2343360e-01  3.9784244e-01 -5.9299165e-01]\n",
      " [ 3.8322848e-01  3.1003836e-01 -4.4408921e-16 -7.3190130e-02\n",
      "  -4.2846248e-01 -1.9161424e-01 -3.8322848e-01 -6.2007672e-01]\n",
      " [ 1.7696337e-01 -1.8406233e-01  5.7898462e-01 -4.4578448e-01\n",
      "  -3.4711021e-01 -1.2746094e-01  5.1292324e-01  3.2186814e-02]\n",
      " [ 1.7609218e-01  2.3477785e-01 -6.3655090e-01 -8.3614141e-02\n",
      "  -1.5548323e-01 -4.9121940e-01  4.2757443e-01  2.3106508e-01]\n",
      " [-4.1918561e-01  1.2953548e-01  6.6613381e-16  5.4872108e-01\n",
      "  -4.6866375e-01  2.0959280e-01  4.1918561e-01 -2.5907096e-01]\n",
      " [-5.5770274e-02  1.3681313e-01 -3.0541489e-01 -4.6801242e-01\n",
      "  -4.0357655e-01  6.5753537e-01 -1.1831383e-01  2.3797691e-01]]\n"
     ]
    }
   ],
   "source": [
    "xMatrix = np.array([[0,2,1,0,0,0,0,0],\n",
    "              [2,0,0,1,0,1,0,0],\n",
    "              [1,0,0,0,0,0,1,0],\n",
    "              [0,1,0,0,1,0,0,0],\n",
    "              [0,0,0,1,0,0,0,1],\n",
    "              [0,1,0,0,0,0,0,1],\n",
    "              [0,0,1,0,0,0,0,1],\n",
    "              [0,0,0,0,1,1,1,0]], dtype=np.float32)\n",
    "\n",
    "X_tensor = tf.convert_to_tensor(xMatrix, dtype=tf.float32)\n",
    "\n",
    "# tensorflow \n",
    "with tf.Session() as sess:\n",
    "    s, U, Vh = sess.run(tf.svd(X_tensor, full_matrices=False))\n",
    "    \n",
    "print(U)\n",
    "print(s)\n",
    "print(Vh)\n",
    "\n",
    "# numpy \n",
    "la = np.linalg\n",
    "U, s, Vh = la.svd(xMatrix, full_matrices=False)\n",
    "\n",
    "print(U)\n",
    "print(s)\n",
    "print(Vh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "323ebed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([4.1594949e-01, 2.0839056e-01, 1.9092928e-01, 8.3643854e-02,\n",
      "       5.5549424e-02, 2.4604747e-02, 2.0932643e-02, 3.5754010e-16],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "xMatrix = np.array([[0,2,1,0,0,0,0,0],\n",
    "              [2,0,0,1,0,1,0,0],\n",
    "              [1,0,0,0,0,0,1,0],\n",
    "              [0,1,0,0,1,0,0,0],\n",
    "              [0,0,0,1,0,0,0,1],\n",
    "              [0,1,0,0,0,0,0,1],\n",
    "              [0,0,1,0,0,0,0,1],\n",
    "              [0,0,0,0,1,1,1,0]], dtype=np.float32)\n",
    "\n",
    "def pca(mat):\n",
    "    mat = tf.constant(mat, dtype=tf.float32)\n",
    "    mean = tf.reduce_mean(mat, 0)\n",
    "    less = mat - mean\n",
    "    s, u, v = tf.svd(less, full_matrices=True, compute_uv=True)\n",
    "\n",
    "    s2 = s ** 2\n",
    "    variance_ratio = s2 / tf.reduce_sum(s2)\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        run = session.run([variance_ratio])\n",
    "    return run\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(pca(xMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13ad0476",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'\n",
    "\n",
    "path = tf.keras.utils.get_file('mnist.npz', DATA_URL)\n",
    "with np.load(path) as data:\n",
    "  train_examples = data['x_train']\n",
    "  train_labels = data['y_train']\n",
    "  test_examples = data['x_test']\n",
    "  test_labels = data['y_test']\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "numNeuronsInDeepLayer = 30\n",
    "w1 = tf.Variable(tf.truncated_normal([784, numNeuronsInDeepLayer]))\n",
    "b1 = tf.Variable(tf.truncated_normal([1, numNeuronsInDeepLayer]))\n",
    "w2 = tf.Variable(tf.truncated_normal([numNeuronsInDeepLayer, 10]))\n",
    "b2 = tf.Variable(tf.truncated_normal([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dffc8447",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NpzFile' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m sess\u001b[38;5;241m.\u001b[39mrun(tf\u001b[38;5;241m.\u001b[39mglobal_variables_initializer())\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):\n\u001b[0;32m---> 47\u001b[0m     batch_xs, batch_ys \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241m.\u001b[39mnext_batch(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     48\u001b[0m     sess\u001b[38;5;241m.\u001b[39mrun(step, feed_dict\u001b[38;5;241m=\u001b[39m{x: batch_xs,\n\u001b[1;32m     49\u001b[0m                               y: batch_ys})\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NpzFile' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    sigma = tf.div(tf.constant(1.0), tf.add(tf.constant(1.0), tf.exp(tf.negative(x))))\n",
    "    return sigma\n",
    "\n",
    "# wx+b, sigmoid \n",
    "z1 = tf.add(tf.matmul(x, w1), b1)\n",
    "a1 = sigmoid(z1)\n",
    "z2 = tf.add(tf.matmul(a1, w2), b2)\n",
    "a2 = sigmoid(z2)\n",
    "\n",
    "loss = tf.subtract(a2, y)\n",
    "\n",
    "# дериватив(sigmoid)=sigmoid*(1-sigmoid)\n",
    "def sigmaprime(x):\n",
    "    return tf.multiply(sigmoid(x), tf.subtract(tf.constant(1.0), sigmoid(x)))\n",
    "\n",
    "dz2 = tf.multiply(loss, sigmaprime(z2))\n",
    "db2 = dz2\n",
    "dw2 = tf.matmul(tf.transpose(a1), dz2)\n",
    "\n",
    "da1 = tf.matmul(dz2, tf.transpose(w2))\n",
    "dz1 = tf.multiply(da1, sigmaprime(z1))\n",
    "db1 = dz1\n",
    "dw1 = tf.matmul(tf.transpose(x), dz1)\n",
    "\n",
    "eta = tf.constant(0.5)\n",
    "step = [\n",
    "    tf.assign(w1,\n",
    "              tf.subtract(w1, tf.multiply(eta, dw1)))\n",
    "    , tf.assign(b1,\n",
    "                tf.subtract(b1, tf.multiply(eta,\n",
    "                                             tf.reduce_mean(db1, axis=[0]))))\n",
    "    , tf.assign(w2,\n",
    "                tf.subtract(w2, tf.multiply(eta, dw2)))\n",
    "    , tf.assign(b2,\n",
    "                tf.subtract(b2, tf.multiply(eta,\n",
    "                                             tf.reduce_mean(db2, axis=[0]))))\n",
    "]\n",
    "\n",
    "acct_mat = tf.equal(tf.argmax(a2, 1), tf.argmax(y, 1))\n",
    "acct_res = tf.reduce_sum(tf.cast(acct_mat, tf.float32))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(10000):\n",
    "    batch_xs, batch_ys = data.train.next_batch(10)\n",
    "    sess.run(step, feed_dict={x: batch_xs,\n",
    "                              y: batch_ys})\n",
    "    if i % 1000 == 0:\n",
    "        res = sess.run(acct_res, feed_dict=\n",
    "        {x: data.test.images[:1000],\n",
    "         y: data.test.labels[:1000]})\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a2769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
