{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615fa390",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# All imports\n",
    "import re\n",
    "import string\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords  #stopwords\n",
    "from nltk import word_tokenize,sent_tokenize # tokenizing\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer  # using the Porter Stemmer and Lancaster Stemmer and others\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, \\\n",
    "cohen_kappa_score, f1_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('../datasets/dataset.json') # dataset.json test_data.json\n",
    "\n",
    "data['target'] = data.hasBadWords.apply(lambda x: 1 if x == True else 0)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    dict(\n",
    "        raw_text=data[\"text\"],\n",
    "        labels=data[\"target\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# RANDOM_STATE = 42\n",
    "\n",
    "# df = pd.read_csv('../datasets/current_train_data.csv')\n",
    "\n",
    "# df = shuffle(df, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "# df = df[:1000]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36eda1a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# function to clean and pre-process the text.\n",
    "def clean_text(text):  \n",
    "    \n",
    "    # 1. Removing html tags\n",
    "    text = bs(text,\"lxml\").get_text()\n",
    "    \n",
    "    # 2. Retaining only alphabets.\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \", text)\n",
    "    \n",
    "    # 3. Converting to lower case and splitting\n",
    "    word_tokens = text.lower().split()\n",
    "    \n",
    "    # 4. Remove stopwords\n",
    "    le = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words(\"english\")+ ['14000kbps', 'november', '1080p', 'email', \n",
    "                                                 '4k', 'mp4', 'error', '404', '2022', 'hd'])     \n",
    "    word_tokens = [le.lemmatize(w) for w in word_tokens if not w in stop_words]\n",
    "    \n",
    "    cleaned_review = \" \".join(word_tokens)\n",
    "    return cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc64b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df.raw_text.map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=['raw_text'], axis=1, inplace=True)\n",
    "df = df[['text', 'labels']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52071cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.20, stratify=df.labels, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e840f6",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(\n",
    "    ngram_range=(1, 3)\n",
    ")\n",
    "\n",
    "X_train = vec.fit_transform(df_train.text)\n",
    "X_test = vec.transform(df_test.text)\n",
    "\n",
    "y_train = df_train.labels\n",
    "y_test = df_test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b5076",
   "metadata": {},
   "source": [
    "# 30k\n",
    "Каппа-коэффициент Коэна:  0.8765533700929965\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00      5946\n",
    "           1       0.98      0.80      0.88        54\n",
    "\n",
    "    accuracy                           1.00      6000\n",
    "   macro avg       0.99      0.90      0.94      6000\n",
    "weighted avg       1.00      1.00      1.00      6000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5266f519",
   "metadata": {},
   "source": [
    "# 50k\n",
    "Каппа-коэффициент Коэна:  0.938671923783697\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00      9907\n",
    "           1       0.97      0.91      0.94        93\n",
    "\n",
    "    accuracy                           1.00     10000\n",
    "   macro avg       0.98      0.96      0.97     10000\n",
    "weighted avg       1.00      1.00      1.00     10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606dfe21",
   "metadata": {},
   "source": [
    "# Using MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36651055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a8b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    acc = accuracy_score(actual, pred)\n",
    "    return rmse, mae, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b1414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MLflow Version:', mlflow.version.VERSION)\n",
    "mlflow.set_tracking_uri('http://localhost:8990')\n",
    "print('Tracking URI:', mlflow.tracking.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'LogReg_Hyperparameters_Search'\n",
    "try:\n",
    "    # creating a new experiment\n",
    "    exp_id = mlflow.create_experiment(name=experiment_name)\n",
    "except Exception as e:\n",
    "    exp_id = mlflow.get_experiment_by_name(experiment_name).experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8a217",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# if 'BW' not in os.listdir():\n",
    "#     os.mkdir('BW')\n",
    "    \n",
    "# solvers = ['liblinear', 'newton-cg', 'lbfgs','sag', 'saga']\n",
    "# penalties = ['l1', 'l2']\n",
    "# c_values = [5.0, 10.0, 100.0]\n",
    "# # max_iter = [100, 1000, 2000, 10000]\n",
    "# l1_ratios = [1.0, 0.2, 0.1, 0.01, 0.001]\n",
    "\n",
    "# for c in c_values:\n",
    "#     for l1_ratio in l1_ratios:\n",
    "#         for penalty in penalties:\n",
    "#             for solver in solvers:\n",
    "#                 if solver == 'newton-cg':\n",
    "#                     penalty = 'l2'\n",
    "#                 with mlflow.start_run(experiment_id=exp_id):\n",
    "#                     mlflow.log_artifacts('BW')\n",
    "#                     lr = RidgeClassifier(\n",
    "#                         C=c, \n",
    "#                         l1_ratio=l1_ratio, \n",
    "#                         penalty=penalty, \n",
    "#                         solver=solver,\n",
    "#                         random_state=42, \n",
    "#                         fit_intercept=True\n",
    "#                     )\n",
    "\n",
    "#                     lr.fit(X_train, y_train)\n",
    "#                     y_pred = lr.predict(X_test)\n",
    "\n",
    "#                     rmse, mae, acc = eval_metrics(y_test, y_pred)\n",
    "#                     cohen_kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "#                     mlflow.log_param('C', c)\n",
    "#                     mlflow.log_param('l1_ratio', l1_ratio)\n",
    "#                     mlflow.log_param('solvers', solver)\n",
    "#                     mlflow.log_param('penalty', penalty)\n",
    "\n",
    "#                     mlflow.log_metric('rmse', rmse)\n",
    "#                     mlflow.log_metric('mae', mae)\n",
    "#                     mlflow.log_metric('acc', acc)\n",
    "#                     mlflow.log_metric('Cohen Kappa', cohen_kappa)\n",
    "#                 #     mlflow.log_metrics({'rmse': rmse, 'mae': mae, 'Cohen Kappa': cohen_kappa})\n",
    "\n",
    "#                     mlflow.sklearn.log_model(lr, 'LogisticRegression_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d629decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'BW' not in os.listdir():\n",
    "    os.mkdir('BW')\n",
    "    \n",
    "solvers = ['cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga',]\n",
    "penalties = ['l1', 'l2']\n",
    "alphas = [0.1, 0.5, 10.0, 100.0, 1000.0]\n",
    "# max_iter = [100, 1000, 2000, 10000]\n",
    "l1_ratios = [1.0, 0.2, 0.1, 0.01, 0.001]\n",
    "\n",
    "for alpha in alphas:\n",
    "            for solver in solvers:\n",
    "                with mlflow.start_run(experiment_id=exp_id):\n",
    "                    mlflow.log_artifacts('BW')\n",
    "                    lr = RidgeClassifier(\n",
    "                        alpha=alpha, \n",
    "                        solver=solver,\n",
    "                        random_state=42,\n",
    "                        positive=False,\n",
    "                        fit_intercept=False\n",
    "                    )\n",
    "\n",
    "                    lr.fit(X_train, y_train)\n",
    "                    y_pred = lr.predict(X_test)\n",
    "\n",
    "                    rmse, mae, acc = eval_metrics(y_test, y_pred)\n",
    "                    cohen_kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "                    mlflow.log_param('alpha', alpha)\n",
    "                    mlflow.log_param('solvers', solver)\n",
    "\n",
    "                    mlflow.log_metric('rmse', rmse)\n",
    "                    mlflow.log_metric('mae', mae)\n",
    "                    mlflow.log_metric('acc', acc)\n",
    "                    mlflow.log_metric('Cohen Kappa', cohen_kappa)\n",
    "                #     mlflow.log_metrics({'rmse': rmse, 'mae': mae, 'Cohen Kappa': cohen_kappa})\n",
    "\n",
    "                    mlflow.sklearn.log_model(lr, 'LogisticRegression_Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ab4843",
   "metadata": {},
   "source": [
    "# Searching runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f708567",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.search_runs(exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140fe6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = 'metrics.acc > .95'\n",
    "df_mlflow = mlflow.search_runs(exp_id, search_query)\n",
    "df_mlflow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df14f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Run IDs with least MAE \\n')\n",
    "\n",
    "for run in df_mlflow['run_id'][df_mlflow['metrics.mae'] == df_mlflow['metrics.mae'].min()].values:\n",
    "    print(run, end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a0802a",
   "metadata": {},
   "source": [
    "# Getting details of a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1705660",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "client.get_run(run_id='a415049b6f5e463c9266e37b6632a71b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59101de2",
   "metadata": {},
   "source": [
    "# Serving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4434cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow models serve --model-uri mlflow-artifacts:/161047726410345551/92b54a97fc064b7daf2c2bb48593b99a/artifacts/LogisticRegression_Model/model.pkl -p 5600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa7163",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# sample_text = [\"\"\"trampling footfetish crushing footjob feet femdom extreme smoking facestanding facesitting mistress heels boots worship domination bdsm whip torture girls women slave bondage dangling humiliation submission ballbusting spanking facetrampling whipping sandals shoes stiletto pain sadism sadistic princess queen facestanting facebusting spitting nipple torture barefeet licking supremacy skin leather pvc latex marks tight high metal jumps footjobs slapping spanking handcuff mistress slave daemonia sapphiria the balck whip lady juliette lilith babalon  deabolika vanesia hypnos candy sadik angels sadik girls womenweight mellyfeet mellydom italian padrone lucignolo bad badcloster badchoice mysapce erotismo erotic nude\"\"\"]\n",
    "# sample_text = [\"\"\"jerk instruction asian goddess masturbation encouragement gag talk asian goddess asian princess femdom female domination female supremacy gag talk cleave gag joi jerk instruction masturbation instruction jerk encouragement astrodomina damsel distress rope bondage tape bondage\"\"\"]\n",
    "# sample_text = [\"\"\"Well now, buxom powerhouse beauty, Charlie, must have been eating cheese or something equally ‘mind-influencing' shortly before bedtime, ‘cause she's having some mondo creepyass dreamage! All to do with absolute captivity, you know, tight bondage and even tighter gags? As she fitfully starts and stutters, gagged and bound alongside her best friend, blonde saucepot, Hannah, for some bizarre reason, her dreams shift and suddenly she's alone and facedown on the bed, struggling intensely, a mega tight black cloth cleave gag keeping her completely muzzled, and yet still she gag-enthuses passionately, wriggling hard like a fish out of the bowl and totally tied up and helpless... then the dream shifts back again and she's coming around alongside her equally scantily clad friend, who is gagged firmly with tape. As the pair - is this still a dream, or what? - come around and realise they are bound and gagged; cue yet another wondrous moment of sexy wriggling, gag talking and energised attempts to escape the stringent ropes. But, of course, they are too tight! And now all these hapless stunners can do is writhe and moan in their underwear on the bed, pondering who, in Charlie's dream, has done this to them! When their twilit captor finally shows himself, the furious babes protest miraculously into their gags, but he ignores them. In Charlie's dreams he is a dark burglar, intent on molesting them, and relieving them of all their homely possessions. Nice. And, as if to demonstrate, he forces a  new gag around the indignant yapper of Charlie as Hannah struggles on, and unleashes her truly magnificent boobies, bouncing them around for his total pleasure, Then the newly bandanna cleave gagged babe is left again to struggle and strain next to her similarly now boob-revealed chum. Both girls are first tickled and spanked and then shut away to continue their tied up endeavours. After a while of very tasty squirming, they suddenly hatch the utterly unintelligible (and this is precisely why it's so damned sexy) plot to wriggle to their feet and hop away. This they ultimately acheive in one incredibly potent scene but are soon recaptured and both carried jiggling and protesting HARD over the bad guy's shoulder. The ever-resisting hotties are shoved rudely against the bedroom wall and left again to twist and buck, shaking their massive tits all over the place. Next up, as a punishment for their wholly unacceptable escape attempts, the pair are firmly trussed in a hallway and massively gagged with hardcore microfoam tape wraparounds. FEEL them cheeks BULGE, Peeps! Wow, this dream is rapidly descending into the stuff of nightmare - for them. For US, it's the ultimate thrill, right? And, as the amazingly barefoot honnies struggle and emote with total sexiness, we must pinch ourselves every once in a while, surely, to see if we really are awake ourselves.... It doesn't get much more exciting that this, as these two Herculean beauties smash it again and again as the ultimate pair of feisty damsels, and for our complete pleasure.****\n",
    "# Wow, this incredibly kinky dream of Young Charlie's seems to have been going on a long time, and ratcheting up in intensity as it progresses to boot! Now, the phantom burglar has left the babes bound and gagged in an upstairs hallway where they pluckily communicate with quite scintillating vigour to one another through their massively suppressive microfoam tape wrap muzzles. They cannot say a WORD. Perfecto! What they CAN do is mmmmpppphhhh like crazy and jiggle their massive boobs around while also flexing their sexy bare feet as they struggle and strain, trying urgently to loosen those damned ropes What they actually succeed in doing is tightening them even more, and now things are getting more nightmarish as the ethereal (get the picture?) crook materialises once more and ropes both hotties one by one into complete and ruthlessly close hogties, but not before manhandling and abusing them both with pervy feel ups and spankings, even wrapping his rope tightly around Charlie's massive boobs, squeezing them ultra tightly as she protests indignity. Poor Hannah, roped into her hogtie already, can't even turn around to see what the creep is doing to her friend. The totally incapacitated duo are soon left to struggle passionately, facedown on the rug, wriggling and grunting with the pure exertion of bouncing around on their boobs, their sexy legs drawn up uncomfortably behind them in these wicked-close hogties! No escape, just an urgent wigglefest as the babes try repeatedly - and furiously - to communicate with one another through their overwhelming tape wrap gags. Later, the bad guy is back, and to add to their current woes, repeatedly winds black electricians' tape over the top of their already mondo-gags. This guy must be nuts, but, we are most grateful for his creativity, no doubt. Now the utterly helpless stunners must struggle and roll and twist their way through the final phases of Charlie's incredibly hot bondage dream. We wonder when she'll ever wake up, but would keenly encourage her to continue napping if these are the kind of night-time fancies she experiences. Good for you, Charlie, and thank you, you saucy little beauts for putting on one hell of a lucid (for a dream) action show as you galvanically buck and moan your respective ways to bondage supremacy. Our collective pulse is now through the roof, thanks to you, gals! Happy Effing New Year, Folks. Just  you WAIT to see what thrills 2014 holds here at Borderland Bound!!\"\"\"]\n",
    "sample_text = [\"strap on dildo fucking male strap on amateur forced feminization strap on bondage whipping caning dildo female domination cross dressing spanking humiliation sissy slut big tits MILF blonde BDSM i sissy training dildo blow job        \"]\n",
    "clean_sample_text = clean_text(sample_text[0])\n",
    "sample_vec = vec.transform(sample_text)\n",
    "pred = lr.predict(sample_vec)\n",
    "\n",
    "print(\"Has bad word\" if pred[0] == 1 else \"Clear text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f20a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv('../datasets/current_train_data.csv')\n",
    "df_val = df_val[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23072653",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"text\"] = df_val.raw_text.map(clean_text)\n",
    "df_val.drop(labels=['raw_text'], axis=1, inplace=True)\n",
    "df_val = df_val[['text', 'labels']]\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbe5ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(\n",
    "    ngram_range=(1, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5327a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc974e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_to_vec = df_val['text']\n",
    "vectors = vec.fit_transform(str_to_vec)\n",
    "df_val['predict'] = lr.predict(vectors)\n",
    "df_val.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
