{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "484c5d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:57:32.336185: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selectolax.parser import HTMLParser\n",
    "import re\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import keyboard\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict, Counter  # For word frequency\n",
    "\n",
    "# import logging  # Setting up the loggings to monitor gensim\n",
    "# logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af9744db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/adwiz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/adwiz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3419d1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86439, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data loading and preparation\n",
    "data = pd.read_json('../datasets/dataset.json')\n",
    "mapping = {False: 0, True: 1}\n",
    "data.replace({'hasBadWords': mapping}, inplace=True)\n",
    "# data.hasBadWords = data.hasBadWords.apply(lambda x: 1 if x == True else 0)\n",
    "data.rename(columns={\"hasBadWords\": \"labels\"}, inplace=True)\n",
    "data.drop(['violation'], axis=1, inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d951963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My Favorite Slut</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>girlfriends sit on each other's faces with the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bound beauty kisses her girlfriend</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MORGAN - Anytime - Nail Painting On The Slave'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRANSGENDER COACHING (wmv) PART 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0                                   My Favorite Slut       0\n",
       "1  girlfriends sit on each other's faces with the...       0\n",
       "2                 bound beauty kisses her girlfriend       0\n",
       "3  MORGAN - Anytime - Nail Painting On The Slave'...       0\n",
       "4                  TRANSGENDER COACHING (wmv) PART 1       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a22d3b6",
   "metadata": {},
   "source": [
    "# Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb27238a",
   "metadata": {
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "def preprocess(text, stop_words, punctuation_marks): #, morph):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    preprocessed_text = []\n",
    "    for token in tokens:\n",
    "        if token not in punctuation_marks:\n",
    "            lemma = token #morph.parse(token)[0].normal_form\n",
    "            if lemma not in stop_words:\n",
    "                preprocessed_text.append(lemma)\n",
    "    return ' '.join(preprocessed_text)\n",
    "\n",
    "punctuation_marks = ['!', ',', ';', \"'\", '(', ')', ':', '-', '--', '', '?', '@', '....', '~',\n",
    "                     '.', '..', '...', '<', '>', '=', '\\'\\'', '//', '»', '|', '’', '`', '+'\n",
    "                     '\\\"\\\"', '</', '&', '/', '#', '\\'', '*', '``', '%', '[', ']', '{', '}']\n",
    "\n",
    "stop_words = stopwords.words('english') + ['14000kbps', \"n't\", \"'s\", \"'m\", 'mp4', 'error', '404']\n",
    "morph = pymorphy2.MorphAnalyzer(lang='uk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39168897",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    \"\"\"\n",
    "    Given a text, cleans and normalizes it. Feel free to add your own stuff.\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    # Replace ips\n",
    "    s = re.sub(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', ' _ip_ ', s)\n",
    "    # Isolate punctuation\n",
    "    s = re.sub(r'([.\\(\\)\\!\\?\\-\\\\\\/\\,])', r' \\1 ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "    # Replace numbers and symbols with language\n",
    "    s = s.replace('&', ' and ')\n",
    "    s = s.replace('@', ' at ')\n",
    "    s = s.replace('0', ' zero ')\n",
    "    s = s.replace('1', ' one ')\n",
    "    s = s.replace('2', ' two ')\n",
    "    s = s.replace('3', ' three ')\n",
    "    s = s.replace('4', ' four ')\n",
    "    s = s.replace('5', ' five ')\n",
    "    s = s.replace('6', ' six ')\n",
    "    s = s.replace('7', ' seven ')\n",
    "    s = s.replace('8', ' eight ')\n",
    "    s = s.replace('9', ' nine ')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd66b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:1000].apply(lambda row: str(row.text), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "842a642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the rows with \"Sci\"\n",
    "# identify partial string\n",
    "# discard = [\"<dev\"]\n",
    "  \n",
    "# # drop rows that contain the partial string \"dev\"\n",
    "# data[~data.text.str.contains('|'.join(discard))]\n",
    "\n",
    "data = data[data['text'].str.contains('<div')==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13955f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My Favorite Slut</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>girlfriends sit on each other's faces with the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bound beauty kisses her girlfriend</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MORGAN - Anytime - Nail Painting On The Slave'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRANSGENDER COACHING (wmv) PART 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83594</th>\n",
       "      <td>ebony,hotwife,wife,swinger,cuckold,bigass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83595</th>\n",
       "      <td>ssbhm, bhm, ffa, female fat admire, fat admire...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83596</th>\n",
       "      <td>Feet in heels, sexy shoes, high heels, high he...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83597</th>\n",
       "      <td>foot fetish, breeding, kinky, fetish porn, bon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83598</th>\n",
       "      <td>Fetish Content, Ellie Boulder, Ellie Boulder P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77496 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  labels\n",
       "0                                       My Favorite Slut       0\n",
       "1      girlfriends sit on each other's faces with the...       0\n",
       "2                     bound beauty kisses her girlfriend       0\n",
       "3      MORGAN - Anytime - Nail Painting On The Slave'...       0\n",
       "4                      TRANSGENDER COACHING (wmv) PART 1       0\n",
       "...                                                  ...     ...\n",
       "83594          ebony,hotwife,wife,swinger,cuckold,bigass       0\n",
       "83595  ssbhm, bhm, ffa, female fat admire, fat admire...       0\n",
       "83596  Feet in heels, sexy shoes, high heels, high he...       0\n",
       "83597  foot fetish, breeding, kinky, fetish porn, bon...       0\n",
       "83598  Fetish Content, Ellie Boulder, Ellie Boulder P...       0\n",
       "\n",
       "[77496 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0838e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[:100].apply(lambda row: bs(row['text']).get_text().replace('\\n',' '),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0021f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:100].apply(lambda row: preprocess(row.text, punctuation_marks, stop_words), axis=1) #, morph), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a240074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['text_preprocessed'] = data.apply(lambda row: bs(row.text).get_text().replace('\\n',' '),axis=1)\n",
    "# data['text_preprocessed'] = data.apply(lambda row: HTMLParser(row.text).body.text(separator=' ').replace('\\n',' '),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f371e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_preprocessed'] = data.apply(lambda row: preprocess(row.text, punctuation_marks, stop_words), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2604d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['text_preprocessed', 'labels', 'text']] # columns reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8f1189a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>favorite slut</td>\n",
       "      <td>0</td>\n",
       "      <td>My Favorite Slut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>girlfriends sit faces asses</td>\n",
       "      <td>0</td>\n",
       "      <td>girlfriends sit on each other's faces with the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bound beauty kisses girlfriend</td>\n",
       "      <td>0</td>\n",
       "      <td>bound beauty kisses her girlfriend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>morgan anytime nail painting slave face</td>\n",
       "      <td>0</td>\n",
       "      <td>MORGAN - Anytime - Nail Painting On The Slave'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transgender coaching wmv part 1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRANSGENDER COACHING (wmv) PART 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text_preprocessed  labels  \\\n",
       "0                            favorite slut       0   \n",
       "1              girlfriends sit faces asses       0   \n",
       "2           bound beauty kisses girlfriend       0   \n",
       "3  morgan anytime nail painting slave face       0   \n",
       "4          transgender coaching wmv part 1       0   \n",
       "\n",
       "                                                text  \n",
       "0                                   My Favorite Slut  \n",
       "1  girlfriends sit on each other's faces with the...  \n",
       "2                 bound beauty kisses her girlfriend  \n",
       "3  MORGAN - Anytime - Nail Painting On The Slave'...  \n",
       "4                  TRANSGENDER COACHING (wmv) PART 1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa66a6",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6fc5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique words\n",
    "def counter_word(text_col):\n",
    "    count = Counter()\n",
    "    for text in text_col.values:\n",
    "        for word in text.split():\n",
    "            count[word] += 1\n",
    "    return count  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d45d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = counter_word(data.text_preprocessed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1cd9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.text_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_words = len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a9cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eea89d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4490eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ed0228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import *\n",
    "word_freq = [i for i in counter.most_common(50)]\n",
    "wd = WordCloud(background_color='white')\n",
    "wd.generate_from_frequencies(dict(word_freq))\n",
    "plt.figure()\n",
    "plt.imshow(wd, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93777ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(data.shape[0] * .8)\n",
    "\n",
    "train = data[:train_size]\n",
    "val = data[train_size:]\n",
    "\n",
    "# Split train and test\n",
    "\n",
    "X_train = train.text_preprocessed.to_numpy()\n",
    "y_train = train.labels.to_numpy()\n",
    "\n",
    "X_val = val.text_preprocessed.to_numpy()\n",
    "y_val = val.labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd92c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.text_preprocessed.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63aea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,  y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dcb04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa6e616",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c7a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize a text corpus by turning each text into sentence of integers\n",
    "\n",
    "tokenizer2 = Tokenizer(num_words=num_unique_words)\n",
    "tokenizer2.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8fce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('../models/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# loading\n",
    "with open('../models/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912fa1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each word have a unique index\n",
    "word_index = tokenizer.word_index\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c86922",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_sequences = tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc2aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[1])\n",
    "print(X_train_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da83e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad the sequences to have the same length\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# max words in a sequence\n",
    "max_length = 20\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "X_val_padded = pad_sequences(X_val_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "X_train_padded.shape, X_val_padded.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba8e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec44ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[10])\n",
    "print(X_train_sequences[10])\n",
    "print(X_train_padded[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8705c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check reversing the indices\n",
    "\n",
    "# flip (key, value)\n",
    "reverse_word_index = dict([(idx, word) for (word, idx) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200bd7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f52afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(sequence):\n",
    "    return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])\n",
    "\n",
    "decoded_text = decode(X_train_sequences[10])\n",
    "\n",
    "print(X_train_sequences[10])\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7b0700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Word embeddings give us a way to use an efficient, dense representation in which similar words have\n",
    "# a similar encoding. Importantly, you do not have to specify this encoding by hand. An embedding is a \n",
    "# dense vector of floating point values (the length of the vector is a parameter you specify)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(num_unique_words, 32, input_length=max_length))\n",
    "\n",
    "# The layer will take as input as integer matrix of size (batcg, input_length)\n",
    "# and the largest integer (i.e. word index) in the input should be no larger than num_words (vocabulary size).\n",
    "# Now model.output_shape is (None, input_length, 32), where `None` is the batch dimension.\n",
    "\n",
    "model.add(layers.LSTM(64, dropout=.1))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a7dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=.001)\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd79bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_padded, y_train, epochs=15, validation_data=(X_val_padded, y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c29bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf00d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(model.history.history)\n",
    "history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fc2cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_df.loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model.predict(X_train_padded)\n",
    "# predictions = [1 if p > .5 else 0 for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train[60:70])\n",
    "# print(y_train[60:70])\n",
    "# print(predictions[60:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95589f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['predictions'] = predictions\n",
    "# train = train[['text_preprocessed', 'labels', 'predictions', 'text']] # columns reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb366b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59591589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv('../datasets/lw2wtf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0144834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = keras.models.load_model('../models/modelSequential.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ba6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_new.predict(X_train_padded)\n",
    "predictions = [1 if p > .5 else 0 for p in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a56eba",
   "metadata": {},
   "source": [
    "# Check sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe408738",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"<p><em><strong>Cadence Lux, Tina Lee Comet &amp; Nate Liquor</strong></em></p>\\r\\n<p>Tina has a hard time finding hot ladies to tie up and fuck. So she hires an older, down on his luck guy, Nate, to catfish for her kinky needs on tindr to lure in a hottie to tie up. Isn't it just Tina's luck that on her first try that Cadence is a lezbo slut who loves being tied up.</p>\\r\\n<div class=\\\"col-sm-12 marginTop10\\\"><strong>Additional Formats</strong><br /><a href=\\\"https://www.clips4sale.com/studio/61965/26849831\\\">HD</a><br /><a href=\\\"https://www.clips4sale.com/studio/61965/26849837\\\">MOBILE</a> <br /><br /><strong>You'll also love</strong> <br /><a href=\\\"https://www.clips4sale.com/studio/61965/25840157\\\"> <img src=\\\"https://imagecdn.clips4sale.com/accounts99/61965/clip_images/WifeHusbandAndCoffeeShopPussy.gif\\\" alt=\\\"\\\" width=\\\"200\\\" height=\\\"113\\\" /> <br />The Wife, The Husband And The Coffee Shop Pussy</a><br /><a href=\\\"https://www.clips4sale.com/studio/61965/25550753\\\"> <img src=\\\"https://imagecdn.clips4sale.com/accounts99/61965/clip_images/FallingForHerAndHerTrap.gif\\\" alt=\\\"\\\" width=\\\"200\\\" height=\\\"113\\\" /> <br />Falling For Her And Her Trap</a></div>\"\n",
    "test_text_preprocessed = bs(raw_text).get_text().replace('\\n',' ')\n",
    "test_text_preprocessed = preprocess(test_text_preprocessed, punctuation_marks, stop_words)\n",
    "test_text_np = np.array([test_text_preprocessed])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_text_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4813d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_text_preprocessed)\n",
    "print(test_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c37a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences_padded = pad_sequences(test_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eddbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = model_new.predict(test_sequences_padded)\n",
    "predictions = [1 if p > .5 else 0 for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da377a5f",
   "metadata": {
    "code_folding": [
     12
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# max words in a sequence\n",
    "max_length = 20\n",
    "\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict, Counter  # For word frequency\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# max words in a sequence\n",
    "max_length = 20\n",
    "\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict, Counter  # For word frequency\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def preprocess(text, stop_words, punctuation_marks): #, morph):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    preprocessed_text = []\n",
    "    for token in tokens:\n",
    "        if token not in punctuation_marks:\n",
    "            lemma = token #morph.parse(token)[0].normal_form\n",
    "            if lemma not in stop_words:\n",
    "                preprocessed_text.append(lemma)\n",
    "    return ' '.join(preprocessed_text)\n",
    "\n",
    "punctuation_marks = ['!', ',', ';', \"'\", '(', ')', ':', '-', '--', '', '?', '@', '....', '~',\n",
    "                     '.', '..', '...', '<', '>', '=', '==', '\\'\\'', '//', '»', '|', '’', '`', '+',\n",
    "                     '\\\"\\\"', '</', '&', '/', '#', '\\'', '*', '``', '%', '[', ']', '{', '}', '$']\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english') + ['14000kbps', 'https', \"'s\", \"'m\", 'http', 'mp4', 'error', '404']\n",
    "\n",
    "# loading\n",
    "with open('../models/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "model = keras.models.load_model('../models/modelSequential.h5')\n",
    "\n",
    "raw_text = '<p>Socks. Such a simple, common and necessary item. I love wearing socks. Frilly socks, fuzzy socks, reinforced toe and heel socks, sweat socks, lace socks, statement socks! I love finding cute colors to match and contrast my shoes and clothes. I actually sold many pairs of socks during college to cover my club visits. Lucky boys. Also, for animals that do not know how to shut their mouths. \\\"Put a sock in it\\\" literally does work. It is kind of weird how much I enjoy hearing the slurping and sucking sounds coming from the floor beneath me. \\\"Yes, I want that sock sucked cleaned foot mutt. Keep that mouth busy for me like a good boy.\\\"</p>'\n",
    "\n",
    "\n",
    "def predict(sequences):\n",
    "    sequences_padded = pad_sequences(sequences, maxlen=20, padding=\"post\", truncating=\"post\")\n",
    "    predictions = model.predict(sequences_padded)\n",
    "    predictions = [1 if p > .5 else 0 for p in predictions]\n",
    "    return predictions\n",
    "\n",
    "# Data loading and preparation\n",
    "data = pd.read_json('../datasets/neil_ProducerClipSite_rand.json')\n",
    "mapping = {False: 0, True: 1}\n",
    "# data.replace({'hasBadWords': mapping}, inplace=True)\n",
    "# data.hasBadWords = data.hasBadWords.apply(lambda x: 1 if x == True else 0)\n",
    "# data.rename(columns={\"hasBadWords\": \"labels\"}, inplace=True)\n",
    "data.drop(['SiteID', 'Title', 'Description', 'Keywords', 'Bottom'], axis=1, inplace=True)\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d22351",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data['text_preprocessed'] = data.apply(lambda row: bs(row.Top, 'lxml').get_text().replace('\\n',' '), axis=1)\n",
    "data['text_preprocessed'] = data.apply(lambda row: preprocess(row.text_preprocessed, punctuation_marks, stop_words), axis=1)\n",
    "\n",
    "X_val = data.text_preprocessed.to_numpy()\n",
    "X_val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "X_val_padded = pad_sequences(X_val_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "predictions = model.predict(X_val_padded)\n",
    "predictions = [1 if p > .5 else 0 for p in predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768e3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6892604",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c6406",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Top', 'predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a04a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../datasets/last_one.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26191e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json('../datasets/last_one.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eac7a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
