{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "484c5d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selectolax.parser import HTMLParser\n",
    "import re\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict, Counter  # For word frequency\n",
    "\n",
    "# import logging  # Setting up the loggings to monitor gensim\n",
    "# logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af9744db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/adwiz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/adwiz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3419d1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86439, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data loading and preparation\n",
    "data = pd.read_json('../datasets/dataset.json')\n",
    "mapping = {False: 0, True: 1}\n",
    "data.replace({'hasBadWords': mapping}, inplace=True)\n",
    "# data.hasBadWords = data.hasBadWords.apply(lambda x: 1 if x == True else 0)\n",
    "data.rename(columns={\"hasBadWords\": \"labels\"}, inplace=True)\n",
    "data.drop(['violation'], axis=1, inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d951963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My Favorite Slut</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>girlfriends sit on each other's faces with the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bound beauty kisses her girlfriend</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MORGAN - Anytime - Nail Painting On The Slave'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRANSGENDER COACHING (wmv) PART 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0                                   My Favorite Slut       0\n",
       "1  girlfriends sit on each other's faces with the...       0\n",
       "2                 bound beauty kisses her girlfriend       0\n",
       "3  MORGAN - Anytime - Nail Painting On The Slave'...       0\n",
       "4                  TRANSGENDER COACHING (wmv) PART 1       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a22d3b6",
   "metadata": {},
   "source": [
    "# Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb27238a",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def preprocess(text, stop_words, punctuation_marks): #, morph):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    preprocessed_text = []\n",
    "    for token in tokens:\n",
    "        if token not in punctuation_marks:\n",
    "            lemma = token #morph.parse(token)[0].normal_form\n",
    "            if lemma not in stop_words:\n",
    "                preprocessed_text.append(lemma)\n",
    "    return ' '.join(preprocessed_text)\n",
    "\n",
    "punctuation_marks = ['!', ',', ';', '(', ')', ':', '-', '--', '?', '@', '....', '~',\n",
    "                     '.', '..', '...', '<', '>', '=', '»', '|', '’', '`', '+', '$',\n",
    "                     '&', '#',  '*', '``', '%', '[', ']', '{', '}']\n",
    "\n",
    "stop_words = stopwords.words('english') + ['14000kbps', '1080p', \"n't\", \"'s\", '4k', \"'m\", 'mp4', 'error', '404']\n",
    "morph = pymorphy2.MorphAnalyzer(lang='uk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39168897",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    \"\"\"\n",
    "    Given a text, cleans and normalizes it. Feel free to add your own stuff.\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    # Replace ips\n",
    "    s = re.sub(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', ' _ip_ ', s)\n",
    "    # Isolate punctuation\n",
    "    s = re.sub(r'([.\\(\\)\\!\\?\\-\\\\\\/\\,])', r' \\1 ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "    # Replace numbers and symbols with language\n",
    "    s = s.replace('&', ' and ')\n",
    "    s = s.replace('@', ' at ')\n",
    "    s = s.replace('0', ' zero ')\n",
    "    s = s.replace('1', ' one ')\n",
    "    s = s.replace('2', ' two ')\n",
    "    s = s.replace('3', ' three ')\n",
    "    s = s.replace('4', ' four ')\n",
    "    s = s.replace('5', ' five ')\n",
    "    s = s.replace('6', ' six ')\n",
    "    s = s.replace('7', ' seven ')\n",
    "    s = s.replace('8', ' eight ')\n",
    "    s = s.replace('9', ' nine ')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd66b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       My Favorite Slut\n",
       "1      girlfriends sit on each other's faces with the...\n",
       "2                     bound beauty kisses her girlfriend\n",
       "3      MORGAN - Anytime - Nail Painting On The Slave'...\n",
       "4                      TRANSGENDER COACHING (wmv) PART 1\n",
       "                             ...                        \n",
       "995    Captain Next Fucks Hot Wife Laney On Her Husba...\n",
       "996    Captain Next Fucks Hot Wife Laney On Her Husba...\n",
       "997    Captain Next Fucks Hot Wife Laney On Her Husba...\n",
       "998    XY19 - Sexy Chinese Maid Gets Femdom With Vibr...\n",
       "999     The Strongest Reverse Headscissors Contest HDMP4\n",
       "Length: 1000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1000].apply(lambda row: str(row.text), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0838e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[:100].apply(lambda row: bs(row['text']).get_text().replace('\\n',' '),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db0021f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         favorite slut\n",
       "1                           girlfriends sit faces asses\n",
       "2                        bound beauty kisses girlfriend\n",
       "3               morgan anytime nail painting slave face\n",
       "4                       transgender coaching wmv part 1\n",
       "                            ...                        \n",
       "95    real mesmerized housewife brooklyn follows orders\n",
       "96                     kaylia strict hogtie naked floor\n",
       "97                 real mesmerized submissive housewife\n",
       "98                        ehesklave muss füsse lutschen\n",
       "99    uncut buck nekkid fucks creampies polly bundy ...\n",
       "Length: 100, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:100].apply(lambda row: preprocess(row.text, punctuation_marks, stop_words), axis=1) #, morph), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a240074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['text_preprocessed'] = data.apply(lambda row: row.text.replace(r'\\n', '').replace(r'\\r', ' '), axis=1)\n",
    "data['text_preprocessed'] = data.apply(lambda row: bs(row.text).get_text().replace(r'\\n', '').replace(r'\\r', ' ').replace(r',', ' '), axis=1)\n",
    "# data['text_preprocessed'] = data.apply(lambda row: HTMLParser(row.text).body.text(separator=' ').replace('\\n',' '),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dcf377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = \"foot,feet,toe,sole,footjob,toejob,sockjob,nylons,fetish,foot fetish,toes,soles,arch,footjobs,toejobs,amateur,oral,anal,hardcore,cumshot,polished,unpolished,handjobs,oily,handjob,cum,tickling,bondage,kinky,boots,video,clip,dvd,vhs,credit card,vendor,low price,custom,vaseline,tip,wet,homemade,blowjob,blowjobs,tits,titjob,boobs,shaved,pussy,young,foot,feet,toe,sole,footjob,toejob,sockjob,nylons,fetish,foot fetish,toes,soles,arch,footjobs,toejobs,amateur,oral,anal,hardcore,cumshot,polished,unpolished,handjobs,oily,handjob,cum,tickling,bondage,kinky,boots,video,clip,dvd,vhs,credit card,vendor,low price,custom,vaseline,tip,wet,homemade,blowjob,blowjobs,tits,titjob,boobs,shaved,pussy,young,foot,feet,toe,sole,footjob,toejob,sockjob,nylons,fetish,foot fetish,toes,soles,arch,footjobs,toejobs,amateur,oral,anal,hardcore,cumshot,polished,unpolished,handjobs,oily,handjob,cum,tickling,bondage,kinky,boots,video,clip,dvd,vhs,credit card,vendor,low price,custom,vaseline,tip,wet,homemade,blowjob,blowjobs,tits,titjob,boobs,shaved,pussy,young,tease,shoe,sandal,nylon,sandaljob,shoejob,asian,raw,store,footjob,toes,soles,cum,cock,footjob,foot,jobs,soles,toes,foot,fetish,\\r\\nfoot,worship,solesquirters,cum,shot,masturbation,mature,\\r\\nsoles,worship,bitches-feet,worship,feet licking,femdom,mistress,\\r\\nslave,huminilation,facesitting,sexy,footjobs,stocking,\\r\\nworship,cock,soles,trampling,pinching,DARLA,FEET,WIFE,alicia,fucking,interracial,  \\r\\nct,amature,cam,caught,fucking,in,sex,str8,ass,bareback,bb,\\r\\nbreed,cum,inside,raw,bed,boner,cock,guy,penis,sweet,china,\\r\\ndan,singapore,stud,my,room,finger,the,call,can,making,me,\\r\\nmonster,well,fetish,gay,mouth,piss,black,white,amateur,amature,male,\\r\\nsperm,ball,ballbuster,ballbusting,balls,busted,busting,busts,foot,\\r\\ngirl,hot,kick,kicked,kicks,nuts,pink,shoes,sneakers,erotic,\\r\\nhose,knee,nut,painful,panty,pantyhose,testicle,testicles,buster,\\r\\ndefense,demonstration,hit,interview,interviewed,self,18,babe,bare,\\r\\nbarefoot,beach,bikini,blonde,feet,kneed,to,bitch,bitches,blond,\\r\\ngroin,kneeling,back,girls,heel,hurt,pain,ballbusters,boot,boots,heels,\\r\\nsandals,sarah,black,redhead,asian,yellow,green,blue,red,polished,unpolished,long,\\r\\ntoenail,long feet,large,\\r\\nblonde,blowjob,cumshot,facial,fucking,ipod,psp,\\r\\nbang,bondage,gang,mask,men,orgy,redhead,sitter,3-way,3way,\\r\\nanal,brunette,condom,cum,fuck,jizz,load,huge,shoot,suck,tattoo,\\r\\narmpit,core,fetish,katrena,panty , porn , pornstar , soft , softcore ,\\r\\nsolo , star , starr , tall , thong , brazil , oral , sex , sexo , girl ,\\r\\npussy , bicep , cock , dick , face , lick , nipple , penis , swallow ,\\r\\ntaste , twink , uncut , hot , jerk , off , spunk , wank , gay , gratefuldead,\\r\\nhung , me , naked , nude , toe , buzzed , young , fist , fisted , focus , \\r\\norgasm , toys , dildo , first , boobs , dyke , girls , lesbo , lesbos ,\\r\\nlovers , sexy , breast , hottie , fisting , amateur , bj , job , tit , tits ,\\r\\nanus , asshole , public , subway , toying , deep , outdoors , throat , vintage, \\r\\nbig , black , huge , lesbians , strapon , erotic , erotica , model , modeling ,\\r\\nnatural , penthouse , bikini , shower , wet , dont_give_a_fuck,  \\r\\nasian , gay , jack , off , ladyboy , pantyhose , shemale , transsexual ,\\r\\nboys , cum , spunk , wank , guy , muscle , guys , latino , men , sex ,\\r\\nsuck , big , girls , have , tits , amateur , cock , nude , anal , blowjob ,\\r\\nindian , hunks , interracial , gangbang , gonzo , midget , oriental , ass ,\\r\\nbubble , masturbate , trannsexual , trannssexual , tranny , transexual ,\\r\\ntransvestite , ts , tv , japan , japanese , jo , oral , angel , athelete, \\r\\ntwinkle , asia , zen , beach , hairy , straight , boy , cute , hunk , korean ,\\r\\nmasturbation , fuck , twink , butt , filipino , jerkoff , load , 18cm , china, \\r\\nchinese , hk , hong , jerk , kong , bigtits , boobs , busty , cumshot , hardcore,\\r\\nmanga , pussy , toon , bukkake , jerk-off , orgy , 0524 , bulacan , burat ,\\r\\nceu , chupa , hogonoy , malolos , manila , marcelo , pampanga , philippines ,\\r\\npinoy , scanda , tamod , tsupa , dance , dancing , naked , shake , shaking , \\r\\nlovers , scandal , my , jockstrap , outside , stripping , night , vision ,\\r\\njungle , twink. , twinks ,  , dirty,\\r\\namateur , fuck , twink , action , gay , model , big , cock , cum , jerk-off ,\\r\\nload , man , sperm , wank , webcam , gonzo , boyfriend , dicks , me ,\\r\\nmy , privat , boobs , tits , anal , step-daddy , dildo , fetish , older , jo ,\\r\\noutdoor , glory , hole , quicky , bareback , group , orgy , sex , brunette ,\\r\\ncumshot , dick , pounded , sexy , toys , masturbation , str8-bait , nude ,\\r\\ncollege , raw , studs , twinks , blowjob , bigcock , cute , huge , jack , jerking,\\r\\nmasturbate , off , solo , tease , thick , wanking , asian , ejaculation , hard,\\r\\npre-cum , semen , straight , vagina , penis , 18 , young , jizz ,\\r\\nmasturbation , spunk , uncut , shoot , cumming , male , ass , butt , naked ,\\r\\njerks-off , masturbatin , wanks , 18-21 , cam , frat , jerk , skate , skater ,\\r\\nsurfer , eat , \\r\\nanal , ass , bi , bisexual , boner , boy , cum , frat , gay , group , hard, \\r\\nhunk , jock , muscle , pussy , straight , bareback , breeding , cock , ebony,\\r\\ninterracial , raw , fuck , self , video , hardcore , sex , dick , fucking ,\\r\\npenis , swing , swinging-free , double , penetration ,blow , step-brother,\\r\\nbrothers , gangbang , groupsex , hot , male , stud , ball , bizarre , butt,\\r\\ncumming , dildo , fisting , hand , play , chulito , cogida , elsa , elza ,\\r\\ngratis , porno , yummi , rough , smooth , amateur , big , step-daddy , fetish,\\r\\nolder , sperm , 3-way , 3way , blonde , brunette , condom , jizz , load, \\r\\nshoot , suck , tattoo , black , job , big-tits , gonzo , all-sex , m.i.l.f. ,\\r\\nsquirting , cream-pies , cumshot , threeway , blowjob , hentai , manga , toon ,\\r\\nbusty , doggystyle , gag , selfcum , slime , glass , masturbate , solo ,\\r\\nwebcam , latino , latin , spanish-speaking , bear , man , asian , cartoon ,\\r\\nfucked , college , studs , twinks , machine , piss , erect , film , french,\\r\\ngorgeous , men , movie , balls , deep,  \\r\\namature , balls , cbt , cock , dick , fetish , hardcore , jack , jo , nasty,\\r\\noff , penis , pig , play , pnp , prick , stroke , wank , act , cam , caught,\\r\\nfucking , in , sex , str8 , chaps , cockring , exhibitionist , flutiesteak ,\\r\\njackoff , jerkoff , leather , masterbate , wifebeater , gay , male , nude ,\\r\\ndenim , exhibitionism , ripped , shorts , me , outdoors , self , bulge ,\\r\\nnylon , public , asian , fuck , cum , orgasm , fluff , hard , cocks, \\r\\ncumming , general , masturbating , big , jacking , jock , stud , young,\\r\\nebony , interracial , outdoor , bi , glory , gloryhole , hole , oral,\\r\\nsucking , fingering , homemade , video , amateur , ass , butt , friend,\\r\\nkinky , panties , panty , solo , straight , briefs , condom , hairy , load,\\r\\nuncut , underwear , belly , black , breasts , lingerie , pussy , rubbing,\\r\\ntouch , hand , anal , build , handsome , hunks , japanese , moarning , nice ,\\r\\nspandex , feet , face , hot , 18 , bra , hung , jerk , jerking , lad ,\\r\\nshemale ,tranny , dildo , gapped , guy,  \\r\\ncum , down , nylon , jacket , coat , parka , cock , polyamide , shiny, \\r\\nslick , smooth , quilted , filthy , come , insulated , dirty , stained,\\r\\nnuptse , ortalion , padded , fetish , orange , bomber , vest , helmet,\\r\\n ,gloves , mask , ridingboot , zodiac , chestwaders , rubber , pvc , latex ,\\r\\nwanking , cumming , jockstrap , faggot , moobs , pudgy , suited , suit ,\\r\\nsilk , satin , masterbate , living , helly , hansen , charlee , chase ,\\r\\nmilf , step-mom , pornstar , porn , puffy , suck , sucking , pussy , fuck ,\\r\\nfucking , mesh , muscle , shorts , shinnyboy , penis , jizz , hunk ,\\r\\nbig , dick , huge , sperm , ground , baseball , tnf , spunk , perv ,\\r\\n  , thief , puffa , fucker , trench , chubby , trackies , polyester ,\\r\\n18 , 19 , 17 , jackets , pants , snow , sports , hood , breath , sho ,\\r\\nhikaru , west , japanese , asian , snorkel , jackoff , fur , winter ,\\r\\nmasturbation , apparel , strap , pose , mac , raincoat , rain , jerk-off ,\\r\\nwank , jacking , gay , hard , hardcore , hung , men , oral , rimming , sex ,\\r\\nshoot,cum , jerk-off , masturbation , wank , jacking , cock , fuck , fucking ,\\r\\ngay , hard , hardcore , hung , men , oral , rimming , sex , shoot ,\\r\\nshooting , anal , ass , bi , bisexual , boner , boy , frat , group ,\\r\\nhunk , jock , muscle , pussy , straight , toss , twink , ebony , horny ,\\r\\njerk , jizz , office , selfsuck , solo , feet , fetish , foot , sleepy ,\\r\\nbathroom , big , bikini , hot , jo , self , 19 , cums , young , \\r\\njack , masturbate , off , sperm , str8 , amateur , load , man , webcam ,\\r\\ndick , erection , hardon , jerking , orgasm , penis , spunk , wanking , \\r\\njackoff , porn , 18 , cumshot , nude , sweet , y/o , yo , dirty , orgy ,\\r\\nsnowball , sucks , dude , j/o , piss , huge , naked , camo , balls ,\\r\\nmasterbation , smooth , twinks , blow , step-brother , brothers , gangbang ,\\r\\ngroupsex , outdoor , college , mixed , moaning , facial , jerkoff , small,\\r\\nuncut , shot , chest , crossdress , satin , transvestite , tv , underwear ,\\r\\nchained , cushion , homemade , sponge , black , rough , cuffs , \\r\\ncock , hairy , piss , shorts , smoking , cum , fuck , fucking , gay , hard,\\r\\nhardcore , hung , men , oral , rimming , sex , shoot , shooting , ebony,\\r\\nhorny , jerk , jizz , office , cam , male , muscle , pose , big , black, \\r\\ndick , bathroom , bikini , hot , hunk , jo , self , anal , bareback , breeding,\\r\\ninterracial , raw , amateur , jerk-off , load , man , sperm , wank , webcam, \\r\\nboner , erection , hardon , jacking , jerking , masturbation , orgasm , penis ,\\r\\nspunk , wanking , jackoff , porn , huge , bed , dildo , naked , bear , belly ,\\r\\nchub , chubby , fat , off , ass , shower , abercrombie , bi , bisexual ,\\r\\n frat , jock , muscles , muscular , stud , balls , exhibitionisme , masturbate,\\r\\n , stroking , fucked , nipple , sweaty , tattoo , cumshot , cut , jerkoff ,\\r\\n thick , asshole , boy , dirty , fart , finger , fingering , hole , manhole ,\\r\\n, nice ,  ,  , facial , chest , yummi , rough , smooth , cuffs , \\r\\nhand , pecker , soft , boyfriend , dicks , me , my , private , masterbate ,\\r\\nandre , dre ,smothering,worship,shoes,shoejob,sandals,cock,cumshot,cum,shoes,shoejob,\\r\\nsandals,cock,shoejob,goddess,female,humiliation,bitchs,lave,dreamgirls,socks,\\r\\nhi,heels,licking,snif,face,sit,sitting,girls,girl,roomate,panties,panty,ass,butt,\\r\\nbum,sub,masorotica,FJ,HJ,Oil,Lube,blonde,nylon,lesbians,breanna,productions,\\r\\nboot,boots,lick,licking,financial,domination,candid,finger,hand,trample,couch,ring,\\r\\nasian,spreading\"\n",
    "# print(bs(s).get_text().replace('\\r', '').replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f371e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_preprocessed'] = data.apply(lambda row: preprocess(row.text_preprocessed, punctuation_marks, stop_words), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "842a642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the rows with \"Sci\"\n",
    "# identify partial string\n",
    "discard = [\"<div \", \"<p \", \"<span \", \"<p>\", \"<div>\", \"<h\", \"<input \", \"center>\", \"<a \", \n",
    "           \"<td>\", \"<\", \">\", \"            \", \"Ø\"]\n",
    "  \n",
    "# # drop rows that contain the partial string \"dev\"\n",
    "# data[~data.text.str.contains('|'.join(discard))]\n",
    "\n",
    "data = data[~data.text.str.contains('|'.join(discard))]#data[~data['text'].str.contains('<div' or '<p>' or '<b'or '<br>' or '&nbsp' or '=')==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13955f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My Favorite Slut</td>\n",
       "      <td>0</td>\n",
       "      <td>favorite slut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>girlfriends sit on each other's faces with the...</td>\n",
       "      <td>0</td>\n",
       "      <td>girlfriends sit faces asses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bound beauty kisses her girlfriend</td>\n",
       "      <td>0</td>\n",
       "      <td>bound beauty kisses girlfriend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MORGAN - Anytime - Nail Painting On The Slave'...</td>\n",
       "      <td>0</td>\n",
       "      <td>morgan anytime nail painting slave face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRANSGENDER COACHING (wmv) PART 1</td>\n",
       "      <td>0</td>\n",
       "      <td>transgender coaching wmv part 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83594</th>\n",
       "      <td>ebony,hotwife,wife,swinger,cuckold,bigass</td>\n",
       "      <td>0</td>\n",
       "      <td>ebony hotwife wife swinger cuckold bigass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83595</th>\n",
       "      <td>ssbhm, bhm, ffa, female fat admire, fat admire...</td>\n",
       "      <td>0</td>\n",
       "      <td>ssbhm bhm ffa female fat admire fat admire fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83596</th>\n",
       "      <td>Feet in heels, sexy shoes, high heels, high he...</td>\n",
       "      <td>0</td>\n",
       "      <td>feet heels sexy shoes high heels high heel fet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83597</th>\n",
       "      <td>foot fetish, breeding, kinky, fetish porn, bon...</td>\n",
       "      <td>0</td>\n",
       "      <td>foot fetish breeding kinky fetish porn bondage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83598</th>\n",
       "      <td>Fetish Content, Ellie Boulder, Ellie Boulder P...</td>\n",
       "      <td>0</td>\n",
       "      <td>fetish content ellie boulder ellie boulder por...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61144 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  labels  \\\n",
       "0                                       My Favorite Slut       0   \n",
       "1      girlfriends sit on each other's faces with the...       0   \n",
       "2                     bound beauty kisses her girlfriend       0   \n",
       "3      MORGAN - Anytime - Nail Painting On The Slave'...       0   \n",
       "4                      TRANSGENDER COACHING (wmv) PART 1       0   \n",
       "...                                                  ...     ...   \n",
       "83594          ebony,hotwife,wife,swinger,cuckold,bigass       0   \n",
       "83595  ssbhm, bhm, ffa, female fat admire, fat admire...       0   \n",
       "83596  Feet in heels, sexy shoes, high heels, high he...       0   \n",
       "83597  foot fetish, breeding, kinky, fetish porn, bon...       0   \n",
       "83598  Fetish Content, Ellie Boulder, Ellie Boulder P...       0   \n",
       "\n",
       "                                       text_preprocessed  \n",
       "0                                          favorite slut  \n",
       "1                            girlfriends sit faces asses  \n",
       "2                         bound beauty kisses girlfriend  \n",
       "3                morgan anytime nail painting slave face  \n",
       "4                        transgender coaching wmv part 1  \n",
       "...                                                  ...  \n",
       "83594          ebony hotwife wife swinger cuckold bigass  \n",
       "83595  ssbhm bhm ffa female fat admire fat admire fee...  \n",
       "83596  feet heels sexy shoes high heels high heel fet...  \n",
       "83597     foot fetish breeding kinky fetish porn bondage  \n",
       "83598  fetish content ellie boulder ellie boulder por...  \n",
       "\n",
       "[61144 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2604d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['text_preprocessed', 'labels', 'text']] # columns reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8f1189a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>favorite slut</td>\n",
       "      <td>0</td>\n",
       "      <td>My Favorite Slut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>girlfriends sit faces asses</td>\n",
       "      <td>0</td>\n",
       "      <td>girlfriends sit on each other's faces with the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bound beauty kisses girlfriend</td>\n",
       "      <td>0</td>\n",
       "      <td>bound beauty kisses her girlfriend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>morgan anytime nail painting slave face</td>\n",
       "      <td>0</td>\n",
       "      <td>MORGAN - Anytime - Nail Painting On The Slave'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transgender coaching wmv part 1</td>\n",
       "      <td>0</td>\n",
       "      <td>TRANSGENDER COACHING (wmv) PART 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text_preprocessed  labels  \\\n",
       "0                            favorite slut       0   \n",
       "1              girlfriends sit faces asses       0   \n",
       "2           bound beauty kisses girlfriend       0   \n",
       "3  morgan anytime nail painting slave face       0   \n",
       "4          transgender coaching wmv part 1       0   \n",
       "\n",
       "                                                text  \n",
       "0                                   My Favorite Slut  \n",
       "1  girlfriends sit on each other's faces with the...  \n",
       "2                 bound beauty kisses her girlfriend  \n",
       "3  MORGAN - Anytime - Nail Painting On The Slave'...  \n",
       "4                  TRANSGENDER COACHING (wmv) PART 1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f91ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../datasets/clear_text.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa66a6",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6fc5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique words\n",
    "def counter_word(text_col):\n",
    "    count = Counter()\n",
    "    for text in text_col.values:\n",
    "        for word in text.split():\n",
    "            count[word] += 1\n",
    "    return count  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d45d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = counter_word(data.text_preprocessed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1cd9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.text_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_words = len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a9cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eea89d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4490eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter.most_common(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ed0228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import *\n",
    "word_freq = [i for i in counter.most_common(50)]\n",
    "wd = WordCloud(background_color='white')\n",
    "wd.generate_from_frequencies(dict(word_freq))\n",
    "plt.figure()\n",
    "plt.imshow(wd, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93777ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(data.shape[0] * .8)\n",
    "\n",
    "train = data[:train_size]\n",
    "val = data[train_size:]\n",
    "\n",
    "# Split train and test\n",
    "\n",
    "X_train = train.text_preprocessed.to_numpy()\n",
    "y_train = train.labels.to_numpy()\n",
    "\n",
    "X_val = val.text_preprocessed.to_numpy()\n",
    "y_val = val.labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd92c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.text_preprocessed.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63aea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,  y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dcb04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa6e616",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c7a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize a text corpus by turning each text into sentence of integers\n",
    "\n",
    "tokenizer2 = Tokenizer(num_words=num_unique_words)\n",
    "tokenizer2.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8fce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('../models/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# loading\n",
    "with open('../models/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912fa1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each word have a unique index\n",
    "word_index = tokenizer.word_index\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c86922",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_sequences = tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc2aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[1])\n",
    "print(X_train_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da83e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad the sequences to have the same length\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# max words in a sequence\n",
    "max_length = 20\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "X_val_padded = pad_sequences(X_val_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "X_train_padded.shape, X_val_padded.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba8e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec44ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[10])\n",
    "print(X_train_sequences[10])\n",
    "print(X_train_padded[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8705c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check reversing the indices\n",
    "\n",
    "# flip (key, value)\n",
    "reverse_word_index = dict([(idx, word) for (word, idx) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200bd7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f52afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(sequence):\n",
    "    return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])\n",
    "\n",
    "decoded_text = decode(X_train_sequences[10])\n",
    "\n",
    "print(X_train_sequences[10])\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7b0700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Word embeddings give us a way to use an efficient, dense representation in which similar words have\n",
    "# a similar encoding. Importantly, you do not have to specify this encoding by hand. An embedding is a \n",
    "# dense vector of floating point values (the length of the vector is a parameter you specify)\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(num_unique_words, 32, input_length=max_length))\n",
    "\n",
    "# The layer will take as input as integer matrix of size (batcg, input_length)\n",
    "# and the largest integer (i.e. word index) in the input should be no larger than num_words (vocabulary size).\n",
    "# Now model.output_shape is (None, input_length, 32), where `None` is the batch dimension.\n",
    "\n",
    "model.add(layers.LSTM(64, dropout=.1))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6eecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path('../models/bad_words.model')\n",
    "path.mkdir(exist_ok=True) \n",
    "cpt_filename = '{epoch:02d}_checkpoint_{val_loss:.2f}.hdf5'\n",
    "cpt_path = str(path / cpt_filename)\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(cpt_path, monitor='val_loss', verbose=1, \n",
    "                                                save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a7dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=.001)\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd79bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_padded, y_train, epochs=15, validation_data=(X_val_padded, y_val), verbose=1, \n",
    "          callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c29bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf00d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(model.history.history)\n",
    "history_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fc2cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_df.loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0686509",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../models/bad_words.model/01_checkpoint_0.14.hdf5') # loading weights - model had created erlier\n",
    "loss, acc = model.evaluate(X_val_padded, y_val)\n",
    "print(f'Accuracy of restored model {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b7e466",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('../models/bad_words.model/01_checkpoint_0.14.hdf5')\n",
    "loss, acc = model.evaluate(X_val_padded, y_val)\n",
    "print(f'Accuracy of restored model {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fe5730",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls '../models/bad_words.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_train_padded)\n",
    "predictions = [1 if p > .5 else 0 for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[60:70])\n",
    "print(y_train[60:70])\n",
    "print(predictions[60:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95589f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['predictions'] = predictions\n",
    "train = train[['text_preprocessed', 'labels', 'predictions', 'text']] # columns reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb366b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59591589",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../datasets/wo_html.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a14da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/modelSequential_wo_HTML.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0144834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_new = keras.models.load_model('../models/modelSequential.h5')\n",
    "model_new = keras.models.load_model('../models/bad_words.model/01_checkpoint_0.14.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ba6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_new.predict(X_train_padded)\n",
    "predictions = [1 if p > .5 else 0 for p in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a56eba",
   "metadata": {},
   "source": [
    "# Check sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe408738",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"torture\"\n",
    "test_text_preprocessed = bs(raw_text).get_text().replace('\\n',' ')\n",
    "test_text_preprocessed = preprocess(test_text_preprocessed, punctuation_marks, stop_words)\n",
    "test_text_np = np.array([test_text_preprocessed])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_text_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4813d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_text_preprocessed)\n",
    "print(test_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c37a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences_padded = pad_sequences(test_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eddbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = model_new.predict(test_sequences_padded)\n",
    "predictions = [1 if p > .5 else 0 for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da377a5f",
   "metadata": {
    "code_folding": [
     12
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# max words in a sequence\n",
    "max_length = 20\n",
    "\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict, Counter  # For word frequency\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# max words in a sequence\n",
    "max_length = 20\n",
    "\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict, Counter  # For word frequency\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def preprocess(text, stop_words, punctuation_marks): #, morph):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    preprocessed_text = []\n",
    "    for token in tokens:\n",
    "        if token not in punctuation_marks:\n",
    "            lemma = token #morph.parse(token)[0].normal_form\n",
    "            if lemma not in stop_words:\n",
    "                preprocessed_text.append(lemma)\n",
    "    return ' '.join(preprocessed_text)\n",
    "\n",
    "punctuation_marks = ['!', ',', ';', \"'\", '(', ')', ':', '-', '--', '', '?', '@', '....', '~',\n",
    "                     '.', '..', '...', '<', '>', '=', '==', '\\'\\'', '//', '»', '|', '’', '`', '+',\n",
    "                     '\\\"\\\"', '</', '&', '/', '#', '\\'', '*', '``', '%', '[', ']', '{', '}', '$']\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english') + ['14000kbps', 'https', \"'s\", \"'m\", 'http', 'mp4', 'error', '404']\n",
    "\n",
    "# loading\n",
    "with open('../models/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "model = keras.models.load_model('../models/modelSequential.h5')\n",
    "\n",
    "raw_text = 'nigger'\n",
    "\n",
    "\n",
    "def predict(sequences):\n",
    "    sequences_padded = pad_sequences(sequences, maxlen=20, padding=\"post\", truncating=\"post\")\n",
    "    predictions = model.predict(sequences_padded)\n",
    "    predictions = [1 if p > .5 else 0 for p in predictions]\n",
    "    return predictions\n",
    "\n",
    "# Data loading and preparation\n",
    "data = pd.read_json('../datasets/neil_ProducerClipSite_rand.json')\n",
    "mapping = {False: 0, True: 1}\n",
    "# data.replace({'hasBadWords': mapping}, inplace=True)\n",
    "# data.hasBadWords = data.hasBadWords.apply(lambda x: 1 if x == True else 0)\n",
    "# data.rename(columns={\"hasBadWords\": \"labels\"}, inplace=True)\n",
    "data.drop(['SiteID', 'Title', 'Description', 'Keywords', 'Bottom'], axis=1, inplace=True)\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d22351",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data['text_preprocessed'] = data.apply(lambda row: bs(row.Top, 'lxml').get_text().replace('\\n',' '), axis=1)\n",
    "data['text_preprocessed'] = data.apply(lambda row: preprocess(row.text_preprocessed, punctuation_marks, stop_words), axis=1)\n",
    "\n",
    "X_val = data.text_preprocessed.to_numpy()\n",
    "X_val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "X_val_padded = pad_sequences(X_val_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "predictions = model.predict(X_val_padded)\n",
    "predictions = [1 if p > .5 else 0 for p in predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768e3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6892604",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c6406",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Top', 'predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a04a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../datasets/last_one.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26191e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json('../datasets/last_one.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eac7a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
