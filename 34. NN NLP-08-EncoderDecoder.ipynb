{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a03bdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9145c96",
   "metadata": {},
   "source": [
    "# Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b752b7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_fpath = tf.keras.utils.get_file(\n",
    "    'shakespeare.txt',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "\n",
    "text = codecs.open(data_fpath, 'r', encoding='utf8').read()\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a126f",
   "metadata": {},
   "source": [
    "# Конвертация символов в индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77411941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "65 unique characters\n",
      "Example of the encoded text: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "VOCAB_SIZE = len(vocab) # Количество слов в словаре\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f'Vocab: {vocab}')\n",
    "print(f'{VOCAB_SIZE} unique characters')\n",
    "\n",
    "char2idx = {u: i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "print(f'Example of the encoded text: {text_as_int[:13]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac1828b",
   "metadata": {},
   "source": [
    "# Подготовка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a939be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ['F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '\\n']\n",
      "Target: ['i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '\\n', 'B']\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 1000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "input_seqs = []\n",
    "target_seqs = []\n",
    "\n",
    "num_seqs = len(text_as_int) // (SEQ_LEN + 1)\n",
    "for i in range(num_seqs):\n",
    "    seq = text_as_int[i:i+SEQ_LEN+1]\n",
    "    input_seqs.append(np.array(seq[:-1]))\n",
    "    target_seqs.append(np.array(seq[1:]))\n",
    "    \n",
    "input_seqs = np.array(input_seqs)\n",
    "target_seqs = np.array(target_seqs)\n",
    "\n",
    "input_seqs = input_seqs[:(len(input_seqs)//BATCH_SIZE)*BATCH_SIZE]\n",
    "target_seqs = target_seqs[:(len(input_seqs)//BATCH_SIZE)*BATCH_SIZE]\n",
    "\n",
    "print(f'Input: {[idx2char[i] for i in input_seqs[0][:15]]}')\n",
    "print(f'Target: {[idx2char[i] for i in target_seqs[0][:15]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd0ab1c",
   "metadata": {},
   "source": [
    "# Функция построения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60d2c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(VOCAB_SIZE, 256, batch_input_shape=(batch_size, None)),\n",
    "        tf.keras.layers.Dropout(.1),\n",
    "        tf.keras.layers.GRU(256, return_sequences=True, stateful=True),\n",
    "        tf.keras.layers.Dense(VOCAB_SIZE),\n",
    "    ])\n",
    "    model.build()\n",
    "    return model\n",
    "\n",
    "model = build_model(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d82812c",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41763199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 7s 343ms/step - loss: 3.7050\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 6s 342ms/step - loss: 3.0363\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 2.7804\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 6s 341ms/step - loss: 2.4702\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 2.2498\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 2.0879\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 1.9372\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 1.7813\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 1.6108\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 1.4170\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 1.1985\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.9608\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.7211\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.5101\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.3503\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.2439\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.1752\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.1326\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.1052\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0860\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0732\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.0632\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0566\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0506\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0460\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0424\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0401\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0370\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0354\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0333\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0320\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0308\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0299\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0289\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0276\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0271\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0262\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0258\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0250\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0241\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0239\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.0236\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0230\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0225\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0225\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0222\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0213\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0212\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0213\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0208\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0203\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0200\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.0200\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0198\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0196\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0194\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0190\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0189\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0188\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.0182\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0182\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0181\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0181\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0180\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0177\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0177\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0174\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.0172\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0169\n",
      "Epoch 70/100\n",
      "14/17 [=======================>......] - ETA: 1s - loss: 0.0169"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "\n",
    "history = model.fit(input_seqs,\n",
    "                    target_seqs,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f92ee7",
   "metadata": {},
   "source": [
    "# Создание модели для инференса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02dded95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inf = build_model(1)\n",
    "\n",
    "for i in range(len(model_inf.layers)):\n",
    "    for j in range(len(model_inf.layers[i].weights)):\n",
    "        model_inf.layers[i].weights[j].assign(model.layers[i].weights[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b119ad6e",
   "metadata": {},
   "source": [
    "# Функция генерации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d90db387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, seed, out_len):\n",
    "    \n",
    "    text_generated = []\n",
    "    \n",
    "    # Обнуляем состояние модели\n",
    "    model.reset_states()\n",
    "    \n",
    "    # Конвертируем входную цепочку в индексы\n",
    "    inp = np.array([char2idx[s] for s in seed])\n",
    "    \n",
    "    for i in range(out_len):\n",
    "        \n",
    "        # Получаем предсказания для входной цепочки inp\n",
    "        # pred - матрица размерности (длина цепочки, распределение по классам)\n",
    "        # На первой итерации цикла длина цепочки равна длине seed, а затем длина равна 1\n",
    "        pred = model(inp[None, ...])[0]\n",
    "        \n",
    "        # Для получения символа сэмплируем из распределения\n",
    "        # Больная температура соответствуем более случайному предсказанию символа\n",
    "        temperature = 1.0\n",
    "        pred = pred / temperature\n",
    "        pred_c = tf.random.categorical(pred, num_samples=1)[-1][0].numpy()\n",
    "        \n",
    "        text_generated.append(idx2char[pred_c])\n",
    "        \n",
    "        # Новый вход -- только что сгенерированный символ\n",
    "        inp = np.array([pred_c])\n",
    "    \n",
    "    return (seed + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcc259aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc']\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f9484",
   "metadata": {},
   "source": [
    "# Запуск генератора текста\n",
    "Запускаем генерацию текста, передавая на вход желаемое начало цепочки seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f256eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONTAGUE:\n",
      "Against him first: he's a very dog to the commonalty.\n",
      "\n",
      "Second Citizen:\n",
      "Consider you what services he has done for his country?\n",
      "\n",
      "First Citizen:\n",
      "Very well; and could be content to give him good\n",
      "report fort, but that he pays himself with being proud.\n",
      "\n",
      "Second Citizen:\n",
      "Nay, but speak not maliciously, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superflui\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_inf, seed=u'MONTAGUE:', out_len=500))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipyflow)",
   "language": "python",
   "name": "ipyflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
